---
title: "Week 9 - Git & Parallelization"
author: "Emorie D Beck"
format: 
  revealjs:
    incremental: true
    code-tools: true
    code-copy: true
    code-line-numbers: true
    code-link: true
    preview-links: true
    slide-number: true
    self-contained: true
    fig-height: 4
    fig-width: 6
    fig-align: center
    css: custom.css
    theme: psc290-23
    # highlight-style: atom-one-dark
    margin-left: "0"
    margin-right: "0"
    width: 1400
    # height: 900
    footer: "PSC 290 - Data Management and Cleaning"
    logo: "https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/ucdavis_logo_blue.png"
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r, echo = F}
pkg <- c("knitr", "psych", "palmerpenguins", "lavaan", "future", "plyr", "tidyverse", "furrr")
pkg <- pkg[!pkg %in% rownames(installed.packages())]
if(length(pkg) > 0) map(pkg, install.packages)

library(knitr)
library(psych)
library(lavaan)
library(future)
library(plyr)
library(tidyverse)
library(furrr) # note loading this last ONLY because it depends on tidyverse and will not mask it
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE,	
                      warning = FALSE,
                      results = 'show',
                      fig.width = 4, 
                      fig.height = 4, 
                      fig.retina = 3)
options(htmltools.dir.version = FALSE
        , knitr.kable.NA = "")
```

# Outline

1.  Questions on Homework
2.  Git/GitHub
3.  Parallelization using `future`
4.  `furrr`


## What and why use Git and GitHub?  

[Video](https://www.dropbox.com/s/r4gij79tw8dx1zv/doyle_why_code_git.mp4?dl=0) from Will Doyle, Professor at Vanderbilt University

## What is __version control__?

- [Version control](https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control) is a "system that records changes to a file or set of files over time so that you can recall specific versions later"
- Keeps records of changes, who made changes, and when those changes were made
- You or collaborators take "snapshots" of a document at a particular point in time. Later on, you can recover any previous snapshot of the document.

## How version control works:

- Imagine you write a simple text file document that gives a recipe for yummy chocolate chip cookies and you save it as `cookies.txt`
- Later on, you make changes to `cookies.txt` (e.g., add alternative baking time for people who like "soft and chewy" cookies)
- When using version control to make these changes, you don't save entirely new version of `cookies.txt`; rather, you save the changes made relative to the previous version of `cookies.txt`

## Why use Git and GitHub?
Why use version control when you can just save new version of document?

1. Saving entirely new document each time a change is made is very inefficient from a memory/storage perspective
    - When you save a new version of a document, much of the contents are the same as the previous version
    - Inefficient to devote space to saving multiple copies of the same content
2. When document undergoes lots of changes -- especially a document that multiple people are collaborating on -- it's hard to keep track of so many different documents. Easy to end up with a situation like this:

## Why use Git and GitHub?
[![](https://pbs.twimg.com/media/B9HgQmDIEAALfb4.jpg)](http://www.phdcomics.com/comics/archive.php?comicid=1531)

*Credit: Jorge Chan (and also, lifted this example from Benjamin Skinner's [intro to Git/GitHub lecture](https://edquant.github.io/past/2020/spring/edh7916/lessons/intro.html))*

## What is __Git__? (from git [website](https://git-scm.com/)) {.smaller}

> "Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency"

- Git is a particular version control software created by _The Git Project_
  - [Git is free and open source software](https://git-scm.com/about/free-and-open-source), meaning that anyone can use, share, and modify the software
  - Although Microsoft owns Github (described) below, it thankfully does not own Git!
- Git can be used by:
    - An individual/standalone developer
    - For collaborative projects, where multiple people collaborate on each file

## What is a __Git repository__?

- A Git repository is any project managed in Git
- From [Git Handbook](https://guides.github.com/introduction/git-handbook/) by github.com:
    - A repository "encompasses the entire collection of files and folders associated with a project, along with each fileâ€™s revision history"
    - Because git is a __distributed__ version control system, "repositories are self-contained units and anyone who owns a copy of the repository can access the entire codebase and its history"
- This course is a Git repository ([PSC290 FQ23 repository](https://github.com/emoriebeck/psc290-data-FQ23/))

## What is a __Git repository__?
- Local vs. remote git repository:
    - __Local__ git repository: git repository for a project stored on your machine
    - __Remote__ git repository: git repository for a project stored on the internet
- Typically, a local git repository is connected to a remote git repository
    - You can make changes to local repository on your machine and then __push__ those changes to the remote repository
    - Other collaborators can also make changes to their local repository, push them to the remote repository, and then you can __pull__ these changes into your local repository

## Private vs. public repositories
  - Public repositories: anyone can access the repository
    - e.g., [PSC290 FQ23](https://github.com/emoriebeck/psc290-data-FQ23/), the git repository we created to develop the Rclass2 course is a public repository because we want the public to benefit from this course
  - Private repositories: only those who have been granted access by a repository "administrator" can access the repository
    
## What is __GitHub__?

- [GitHub](https://github.com/) is the industry standard hosting site/service for Git repositories
    - Hosting services allow people/organizations to store files on the internet and make those files available to others
- Microsoft acquired Github in 2018 for $7.5 billion
- Github is where **remote** git repositories live

## Git Workflow {.smaller}

Version control systems that save **differences**:
- Prior to Git, "centralized version control systems" were the industry standard version control systems (From [Getting Started - About Version Control](https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control))
    - In these systems, a central server stored all the versions of a file and "clients" (e.g., a programmer working on a project on their local computer) could "check out" files from the central server
- These centralized version control systems stored multiple versions of a file as "differences"
- The below figure portrays version control systems that store data as changes relative to the base version of each file:    

## Git Workflow

![](https://git-scm.com/book/en/v2/images/deltas.png)

*Credit: [Getting Started - What is Git](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F)*

## Git Workflow

Git stores data as **snapshots** rather than _differences_:

- Git doesn't think of data as differences relative to the base version of each file
- Rather, Git thinks of data as "a series of snapshots of a miniature filesystem" or, said differently, a series of snapshots of all files in the repository
- For files that have changed:
  - the "commit" will save lines that you have changed or added [like "differences"]
  - lines that have not changed will not be re-saved; because these lines have been saved in previous commit(s) that are linked to the current commit

## Git Workflow
- The below figure portrays storing data as a stream of snapshots over time:

![](https://git-scm.com/book/en/v2/images/snapshots.png)

*Credit: [Getting Started - What is Git](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F)*

## What is a __commit__?

- A **commit** is a snapshot of all files in the repository at a particular time
- Example: Imagine you are working on a project (repository) that contains a dozen files
    - You change two files and make a commit
    - Git takes a snapshot of the full repository (all files)
    - Content that remains unchanged relative to the previous commit is stored vis-a-vis a link to the previous commit

## Three components of a Git project

<center>![](https://miro.medium.com/max/686/1*diRLm1S5hkVoh5qeArND0Q.png){width=500px}</center>

*Credit: Lucas Maurer, [medium.com](https://medium.com/@lucasmaurer/git-gud-the-working-tree-staging-area-and-local-repo-a1f0f4822018)*

## Three components of a Git project {.smaller}

1. __Local working directory__ (also called "working tree")
    - This is the area where all your work happens! You are writing Rmd files, debugging R scripts, adding and deleting files
    - These changes are made on your local machine!
    
2. __Git index/staging area__ (`git add <filename(s)>` command)
    - The staging area is the area between your _local working directory_ and the _repository_, where you list changes you have made in the local working directory that you would like to commit to the repository
    
3. __Repository__ (`git commit` command)
    - This is the actual repository where Git permanently stores the changes you've made in the local working directory and added to the staging area

## Git Workflow {.smaller}

Hypothetical work flow to `cookies.txt`:

- ***Add*** changes from _local working directory_ to _staging area_ 
- ***Commit*** changes from _staging area_ to _repository_ 
- Each **commit** to the repository is a different version of the file that represents a snapshot of the file at a particular time 
- Commits are made to **branches** in the repo 
    - By default, a git repository comes with one main branch (typically called **main**) 
    - But we can also create other branches (discussed more later) 

## Git Workflow
- **Local** vs. **remote** repository
    - When you add a change to the _staging area_ and then commit the change to your _repository_, this changes your _local repository_ (i.e., on your computer) rather than your _remote repository_ (i.e., on GitHub)
- If you want to change the _remote repository_ (typically named **origin**), you must ***push*** the change from your _local repository_ to your _remote repository_
- As seen below, each circle represents a **commit**. After you make commits on a branch in your _local repository_ (i.e., **main**), you need to ***push*** them in order for the corresponding branch on the _remote repository_ (i.e., **origin/main**) to be up-to-date with your changes.

## GitHub Desktop

- Practically, in this class, I'm going to show you how to use GitHub Desktop, which is a GUI (graphical user interface) for managing git repositories and commits. 
- Relative to the command line, using a GUI means you're ready to be "up and running with git immediately and don't have to learn bash syntax


## Exercise: Setting Up GitHub Desktop

- Rather than stepping through in the slides, I'm going to have each of you navigate to this link: [https://docs.github.com/en/desktop/overview/getting-started-with-github-desktop](https://docs.github.com/en/desktop/overview/getting-started-with-github-desktop).
- Follow it to the end of Part 1 (Installing and authenticating) and then pause
- Raise your hand if you need help
- If you don't already have a GitHub account and don't want to set one up, work with someone around you

## The basic workflow {.smaller}

### First time
1. **Clone** the repository that you want to work on from GitHub onto your local machine
2. Work on the files/scripts, e.g., `penguins.R`
3. Next, you will **commit** your changes and include an informative message, e.g. "Plot distribution of flipper length"
4. Then, you will **push** your changes to the remote repository

### Subsequent times
1. **Pull** any changes from the remote repository that your collaborators might have made
2. Repeat steps 2-4 above

## Cloning

```{=html}
<div>
  <center>
  <video width="70%" height="60%" controls muted>
  <source src="https://github.com/walice/git-tutorial/raw/master/assets/cloning.mp4" type="video/mp4">
  </video>
  </center>
</div>
```

## Exercise

The repo [walice/git-tutorial](https://github.com/walice/git-tutorial) contains the `penguins.R` script, which works with data from the `palmerpenguins` library.

*Credit: [5 Minute Git](https://github.com/walice/git-tutorial)*

## Work on the files

```{r include=FALSE, warning=FALSE}
library(palmerpenguins)
```

```{r warning=FALSE, fig.align="center", fig.width=7, fig.height=5}
ggplot(penguins, 
       aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + 
  geom_point() +
  labs(title = "Penguin bills") + 
  theme_classic()
```

## Staging your files

![Stage your file](https://raw.githubusercontent.com/walice/git-tutorial/master/assets/staged-file.png)

## Commit your changes

```{=html}
<div>
  <center>
  <video width="70%" height="60%" controls muted>
  <source src="https://github.com/walice/git-tutorial/raw/master/assets/committing.mp4" type="video/mp4">
  </video>
  </center>
</div>
```

## Commit your changes

#### Use an informative commit message
  - (Not great) "Analyze data" `r emo::ji("disappointed")`
  - (Better) "Estimate logistic regression" `r emo::ji("tada")`

#### Have a consistent style
  - Start with an action verb
  - Capitalize message

#### Commits are _cheap_, use them often!

## Push your changes

```{=html}
<div>
  <center>
  <video width="70%" height="60%" controls muted>
  <source src="https://github.com/walice/git-tutorial/raw/master/assets/pushing.mp4" type="video/mp4">
  </video>
  </center>
</div>
```

## Why Use Git/Hub

- Direct link to the Open Science Framework via "Add-ons," so you don't have to maintain / copy files multiple places 
- Easy collaboration with better tools for dealing with conflicts due to remotes
- Easy to restore back to an earlier "snapshot"
- Can directly link to files, data, etc. 
  * by default, the links will be to the "main" 
  * swap this out for "raw" and it will link to the raw file, which will open a raw text page for text files (including .csv) or download (including .docx, .pdf, etc.)
  
# Parallel Processing in R

## Guarding your resources 

- Computers have finite resources 
- A common source of issues in R is a cluttered environment 
   * Objects you aren't using
   * Objects unrelated to whatever you're working on, etc. 

## Cleaning up your environment {.smaller}

- The best ways to avoid issues due to a cluttered environment are: 
  * Always start from a blank environment 
  * Write scripts systematically. You shouldn't be skipping around and should be careful about overwriting objects
  * Save object(s), not your whole workspace to allow you to bring back in things you were working on previously
  * Use object names with clear patterns to allow you clean up your environment
    + `rm(list=ls()[grepl("RQ1", ls()])`
    + `rm(list=ls()[!ls() %in% c("df1", "df2")])`
  * Occasionally call `gc()` after cleaning up your environment

## Guarding your resources

- All of the above guard your __RAM__, but another cause of issues with resources is that you take full advantage of your computing power
- Most modern computers have 8+ physical and virtual cores and powerful graphics cards
- Together, these allow us to parallelize processes, which just means to do multiple different processes in parallel at the same time

## Parallel Processing 

- You've likely used parallel processing in R before
- Many packages, like `lavaan`, `lme4`, and any bootstrapping have an argument called `parallel`, with values like `TRUE`/`FALSE` or "fork"/"multisession"/"multicore"
- This just means that they are using one of many available packages / tools to speed up the estmation of whatever your function is doing

## Why use `future` for parallelization? {.smaller}

- A Unifying Parallelization Framework in R for Everyone
- Require only minimal changes to parallelize existing R code
- â€œWrite once, Parallelize anywhere
- Same code regardless of operating system and parallel backend
- Lower the bar to get started with parallelization
- Fewer decisions for the developer to make
- Stay with your favorite coding style
- Worry-free: globals, packages, output, warnings, errors just work
- Statistically sound: Built-in parallel random number generation (RNG)
- Correctness and reproducibility of highest priority

## Three atomic building blocks

There are three atomic building blocks that do everything we need:

- `f  <- future(expr)` : evaluates an expression via a future (non-blocking, if possible)
- `rs <- resolved(f)` : `TRUE` if future is resolved, otherwise FALSE (non-blocking)
- `v  <- value(f)` : the value of the future expression `expr` (blocking until resolved)

## Example 

To break down what's happening, let's use a bad function, called `slow_sum()`

```{r}
slow_sum <- function(x) {
  sum <- 0
  for (kk in seq_along(x)) {
    sum <- sum + x[kk]
    Sys.sleep(0.1)  # emulate 0.1 second cost per addition
  }
  sum
}
```

*Credit: [future tutorial useR 2022](https://henrikbengtsson.github.io/future-tutorial-user2022)*

## Example 
If we then call, the following, it takes about 10 seconds

```{r}
x <- 1:100
v <- slow_sum(x)
v
#> [1] 5050
```

But we could do the same in future and see that time to evaluate has been cut in half: 

```{r}
library(future)
plan(multisession) # evaluate futures in parallel

x <- 1:100
f <- future(slow_sum(x))
v <- value(f)
#> [1] 5050
```

## Anatomy of `future()` {.smaller}
When we call:

```{r}
f <- future(slow_sum(x))
```

then:

- a future is created, comprising: 
    * the R expression slow_sum(x), 
    * function slow_sum(), and 
    * integer vector x 
- These future components are sent to a parallel worker, which starts evaluating the R expression 
- The `future()` function returns immediately a reference `f` to the future, and before the future evaluation is completed 

## Anatomy of `value()`

When we call:

```{r}
v <- value(f)
```

then:

- the future asks the worker if itâ€™s ready or not (using `resolved()` internally)
- if it is not ready, then it waits until itâ€™s ready (blocking)
- when ready, the results are collected from the worker
- the value of the expression is returned

## Benefits of future: 

- You can keep doing other things while your code runs in the background and then eventually check whether it's done using `resolved()` or `value()`
- You can do multiple different futures at the same time

## Benefits of future: 

When we run code normally, we experience blocking, which means that the next line can't run until the previous one is done. 

```{r}
x_head <- head(x, 50)
x_tail <- tail(x, 50)

v1 <- slow_sum(x_head)         ## ~5 secs (blocking)
v2 <- slow_sum(x_tail)         ## ~5 secs (blocking)
v <- v1 + v2
```

But with future, we can parallelize and continue to run other things: 

```{r}
f1 <- future(slow_sum(x_head)) ## ~5 secs (in parallel)
f2 <- future(slow_sum(x_tail)) ## ~5 secs (in parallel)

## Do other things
z <- sd(x)

v <- value(f1) + value(f2)     ## ready after ~5 secs
```

## Setting up your future backend 

To fully make use of future, you need to understand: 

- parallel backends 
- "workers" 
- globals  
- packages  

## Parallel backends 
- There are multiple ways that you can run parallel processes in R that depend on: 
  - your OS
  - whether you are running local or remote sessions
1. `plan(sequential)`: default, will block 
2. `plan(multisession)`: parallel, no blocking
3. (`plan(future.batchtools::batchtools_slurm)`)
4. (`plan(future.callr::callr, workers = 4)`)
5. More to come

## Workers 
- Remember, `R` resources are finite 
- As a rule of thumb, you don't want to call more resources than you have

:::{.fragment}

```{r}
parallel::detectCores()
```

:::

## Workers 
in `future`, workers are basically the number of cores you want to use for parallel processing

```{r, eval = F}
plan(multisession, workers = 8)
nbrOfWorkers()
#> [1] 8

plan(multisession, workers = 2)
nbrOfWorkers()
#> [1] 2
```

## Workers 
in `future`, workers are basically the number of cores you want to use for parallel processing

```{r, eval = F}
plan(multisession, workers = 2)
nbrOfWorkers()
#> [1] 2

f1 <- future(slow_sum(x_head))
f2 <- future(slow_sum(x_tail))
f3 <- future(slow_sum(1:200))   ## <= blocks here

resolved(f1)
#> [1] TRUE
resolved(f2)
#> [1] TRUE
resolved(f3)
#> [1] FALSE
```

## Globals 

-`globals` is an argument for `future()`. By default, it is set to `TRUE` 
- Alternatively, it could be a character vector including only those globals you want the `future()` call to have access to 

```{r, eval = F}
x_head <- head(x, 50)
x_tail <- tail(x, 50)

plan(multisession, workers = 2)
f1 <- future(slow_sum(x_head), globals = c("slow_sum", "x_head"))
f2 <- future(slow_sum(x_tail), globals = c("slow_sum", "x_head")) ## doesn't work
```

## Packages 
- `packages` is an argument for `future()`. By default, it is set to `NULL`
- Alternatively, it could be a character vector including only those packages you want to import into the parallel calls
  * Useful when working with package conflicts, remote clusters

# `furrr`: `future` + `purrr`

> The goal of furrr is to combine purrrâ€™s family of mapping functions with futureâ€™s parallel processing capabilities. The result is near drop in replacements for purrr functions such as map() and map2_dbl(), which can be replaced with their furrr equivalents of future_map() and future_map2_dbl() to map in parallel.

## `furrr`

- I personally use `furrr` frequently when I need to a bunch of stuff in parallel but not so much I find myself needing to reach for an HPC
- Why? It works just like `purrr` functions but allows me to run them in parallel! 

:::{.fragment}

```{r, eval = F}
plan(multisession, workers = 2)

1:10 %>%
  future_map(rnorm, n = 10, .options = furrr_options(seed = 123)) %>%
  future_map_dbl(mean)
```

:::

## `furrr`
- I also use `furrr` because it works just like future: 
- `future_map(.x, .f, .options = furrr_options())`
  * `furrr_options()` basically takes all the same arguments a typical `future()` call would take, including globals and packages 
- So with very little experience, you can shift an existing `purrr` workflow (or pieces of it) to parallel 

## Exercise 

As a brief exercise, let's revisit some of the latent growth models we ran last week: 

```{r}
gsoep2_lavaan <- readRDS("week9-data.RDS")
```

## Exercise {.smaller}

Below is the lavaan syntax we ran: 

```{r}
mod <- '
  W1 =~ NA*I1_2005 + lambda1*I1_2005 + lambda2*I2_2005 + lambda3*I3_2005
  W2 =~ NA*I1_2009 + lambda1*I1_2009 + lambda2*I2_2009 + lambda3*I3_2009
  W3 =~ NA*I1_2013 + lambda1*I1_2013 + lambda2*I2_2013 + lambda3*I3_2013
  
  i =~ 1*W1 + 1*W2 + 1*W3
  s =~ -1*W1 + 0*W2 + 1*W3
  
  ## intercepts
  I1_2005 ~ t1*1
  I1_2009 ~ t2*1
  I1_2013 ~ t3*1
  
  I2_2005 ~ t1*1
  I2_2009 ~ t2*1
  I2_2013 ~ t3*1
  
  I3_2005 ~ t1*1
  I3_2009 ~ t2*1
  I3_2013 ~ t3*1
  
  ## correlated residuals across time
  I1_2005 ~~ I1_2009 + I1_2013
  I1_2009 ~~ I1_2013
  I2_2005 ~~ I2_2009 + I2_2013
  I2_2009 ~~ I2_2013
  I3_2005 ~~ I3_2009 + I3_2013
  I3_2009 ~~ I3_2013
  
  ## latent variable intercepts
  W1 ~ 0*1
  W2 ~ 0*1
  W3 ~ 0*1
  
  #model constraints for effect coding
  ## loadings must average to 1
  lambda1 == 3 - lambda2 - lambda3
  ## means must average to 0
  t1 == 0 - t2 - t3
  '
```

## Exercise 

And the function we ran: 

```{r}
lavaan_fun <- function(d, trait){
  m <- growth(
    mod
    , data = d
    , missing = "fiml"
  )
  # saveRDS(m, file = sprintf("results/models/%s.RDS", trait))
  return(m)
}
```

## Exercise 

But instead of running the model using `map2()`, let's run it using `future_map2()`

```{r}
start <- Sys.time()
gsoep_nested2 <- gsoep2_lavaan %>%
  group_by(category, trait) %>%
  nest() %>%
  ungroup() %>%
  mutate(m = map2(data, trait, lavaan_fun))
end <- Sys.time()
print(end - start)
# > Time difference of 4.413002 secs
```

## Exercise

In this case, we're only saving a few seconds, but in the case having many more models or models that run longer, this can HUGELY add up

```{r}
start <- Sys.time()
plan(multisession, workers = 5L)
gsoep_nested2 <- gsoep2_lavaan %>%
  group_by(category, trait) %>%
  nest() %>%
  ungroup() %>%
  mutate(m = future_map2(data, trait, lavaan_fun))
end <- Sys.time()
print(end - start)
# Time difference of 2.993128 secs
```

## Caution: Data transfer

>The goal of furrr is to combine purrrâ€™s family of mapping functions with futureâ€™s parallel processing capabilities. The result is near drop in replacements for purrr functions such as map() and map2_dbl(), which can be replaced with their furrr equivalents of future_map() and future_map2_dbl() to map in parallel.

- Better alternative: don't export large objects using `furrr` but save the output to a local environment that can be loaded in later

## Next Week: Review 
- Next week, we'll wrap up with a one hour "overview" highlighting big takeaways, reminders, etc. for the course
- Then, everyone will have the chance to (optionally) share their favorite `R` hacks (hint: this is a good excuse / nudge to remember the bonus points you can get by submitting tidy tuesday style code)
- Finally, we'll have time to work on final projects 

# Acknowledgments
Resources used to create this lecture:

- https://anyone-can-cook.github.io/rclass2/
- https://happygitwithr.com/
- https://henrikbengtsson.github.io/future-tutorial-user2022
- https://furrr.futureverse.org/
- https://github.com/walice/git-tutorial/
- https://edquant.github.io/edh7916/lessons/intro.html
- https://www.codecademy.com/articles/f1-u3-git-setup
