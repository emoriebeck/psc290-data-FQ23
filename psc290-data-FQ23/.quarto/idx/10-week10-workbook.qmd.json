{"title":"Week 10 Workbook","markdown":{"yaml":{"title":"Week 10 Workbook","author":"Emorie D Beck","format":{"html":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true,"self-contained":true}},"editor":"visual","editor_options":{"chunk_output_type":"console"}},"headingText":"Week 10 - Review & Reflection","containsRefs":false,"markdown":"\n\n```{r, echo = F}\npkg <- c(\"knitr\", \"psych\", \"lavaan\", \"future\", \"plyr\", \"tidyverse\", \"furrr\")\npkg <- pkg[!pkg %in% rownames(installed.packages())]\nif(length(pkg) > 0) map(pkg, install.packages)\n\nlibrary(knitr)\nlibrary(psych)\nlibrary(lavaan)\nlibrary(future)\nlibrary(plyr)\nlibrary(tidyverse)\nlibrary(furrr) # note loading this last ONLY because it depends on tidyverse and will not mask it\n```\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, \n                      message = FALSE,\t\n                      warning = FALSE,\n                      results = 'show',\n                      fig.width = 4, \n                      fig.height = 4, \n                      fig.retina = 3)\noptions(htmltools.dir.version = FALSE\n        , knitr.kable.NA = \"\")\n```\n\n\n# Topics\n\n1.  Intro to Base R\n2.  `dplyr`: Manipulating Data\n3.  `tidyr`: Reshaping and Transforming Data\n4.  Codebooks\n5.  `purrr` & Functions\n6.  Review\n7.  Strings, dates, & regex\n8.  Functional Tables & Figures\n9.  GitHub & Parallelization\n10. Today\n\n# Lessons & Takeaways\n\n## Lesson 1\n\n### Always load tidyverse last\n\n-   Always load all packages **at the beginning of a script**\n\n```{r}\nlibrary(psych)\nlibrary(ggdist)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(brms)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(patchwork)\nlibrary(plyr)\nlibrary(tidyverse)\nlibrary(furrr)\n```\n\n-   Note: `tidyverse` loads: `dplyr`, `forcats` (factors), `ggplot2`, `lubrdiate`, `purrr`, `readr`, `stringr`, `tibble`, and `tidyr`\n-   This is good! It reduces the number of packages you have to load and ensures there's no order issues\n\n------------------------------------------------------------------------\n\n### Deal with Conflicts\n\n-   Use the `conflicts()` function to figure out what conflicts you have\n-   Use `package::fnName()` to call a function directly without loading a package / to override conflicts\n    -   e.g., `kableExtra` should be loaded before `tidyverse`, but then `tidyverse` masks `kableExtra::group_rows()`\n\n```{r, eval = F}\nkable(tab) %>%\n  kable_classic(html_font = \"Times\") %>%\n  kableExtra::group_rows(\"Header\", 1, 3)\n```\n\n## Lesson 2\n\n### There is no single way to do anything\n\n-   The best way to do something is a way that you understand or you can introduce the mistakes you're trying to prevent\n\n```{r}\nbfi %>%\n  mutate(\n    sid = 1:n(),\n    E = rowMeans(pick(matches(\"E\\\\d\")), na.rm = T), \n    A = rowMeans(pick(matches(\"A\\\\d\")), na.rm = T), \n    C = rowMeans(pick(matches(\"C\\\\d\")), na.rm = T), \n    N = rowMeans(pick(matches(\"N\\\\d\")), na.rm = T), \n    O = rowMeans(pick(matches(\"O\\\\d\")), na.rm = T)\n  ) %>%\n  ungroup() %>%\n  select(sid, E:O)\n```\n\n```{r}\nbfi %>% \n  mutate(sid = 1:n()) %>%\n  pivot_longer(\n    cols = c(-sid, -gender, -education, -age)\n    , names_to = c(\"trait\", \"item\")\n    , names_sep = -1\n    , values_to = \"value\"\n  ) %>%\n  group_by(sid, trait) %>%\n  summarize(value = mean(value, na.rm = T)) %>%\n  pivot_wider(names_from = \"trait\", values_from = \"value\") %>%\n  ungroup()\n```\n\n## Lesson 3\n\n### Start at the end\n\n-   What do you want your data to look like?\n-   What do they look like now?\n-   Now fill in the middle\n\nHLM / MLM / MEM: RE ex: time, trial, stimuli, group, study, day, w/in person conditions FE ex: gender, baseline age, b/w subject conditions, country, etc. (can also be an RE)\n\nID \\| RE1 \\| RE2 \\| DV \\| FE1\\\n1 \\| 1 \\| 1 \\| 4 \\| 3\\\n1 \\| 1 \\| 2 \\| 3 \\| 3\\\n1 \\| 2 \\| 1 \\| 2 \\| 3\\\n1 \\| 2 \\| 2 \\| 1 \\| 3\\\n2 \\| 1 \\| 1 \\| 5 \\| 1\\\n2 \\| 1 \\| 2 \\| 3 \\| 1\\\n2 \\| 2 \\| 1 \\| 1 \\| 1\\\n2 \\| 2 \\| 2 \\| 2 \\| 1\n\n------------------------------------------------------------------------\n\n### Start at the end\n\nID \\| RE_1_1 \\| RE_1_2 \\| RE+2_1 \\| RE_2_2 \\| FE2 1 \\| 4 \\| 3 \\| 2 \\| 1 \\| 3\\\n2 \\| 5 \\| 3 \\| 1 \\| 2 \\| 1\n\n-   `pivot_longer()`: RE_1_1:RE_2_2\n    -   names_to = c(\"RE1\", \"RE2\")\n    -   values_to = \"DV\"\n    -   names_sep = \"\\_\"\n    -   names_prefix = \"RE\\_\"\n-   Note this is only possible / easy because of the naming scheme! If we had them named \"RE1_1\", this would not have been possible / would have been CONSIDERABLY more difficult\n\n## Lesson 4\n\n### Don't be afraid to split your data into chunks\n\n-   In alignment with starting at the end, a key strategy is knowing how you can **chunk** your data\n-   No right or wrong way to chunk, but some examples are:\n    -   items / values from the same scale / task (e.g., DV across trials / conditions)\n    -   baseline items (from other survey or from baseline wave)\n    -   outcome variables\n    -   descriptive variables\n    -   item-level variables v. composites\n\n## Lesson 5\n\n### Joining data requires a key, so be thoughtful and you'll always be able to put the pieces together\n\n-   The most important thing when splitting data into chunks is to make sure you can put it back together\n-   This requires one (e.g., participant ID) or more (e.g., participant ID, wave) keys that allows R to match the right values together\n-   This should be the last thing you do\n    -   Please don't create mega datasets where you tack things on to the raw data as you go\n    -   This will eat RAM and make your life harder (and sometimes could end up in you accidentally sharing identifying information!!)\n\n## Lesson 6\n\n### One of the most important skills is getting comfortable making data move flexibly from wide to long\n\n-   Remember our example above? Without knowledge of how to do so, it would have been almost impossible\n-   It's okay if it takes more than one step! That's better than manually moving stuff in excel and not creating a reproducible path!\n\n```{r}\nbfi %>% \n  mutate(sid = 1:n()) %>%\n  pivot_longer(\n    cols = c(-sid, -gender, -education, -age)\n    , names_to = c(\"trait\", \"item\")\n    , names_sep = -1\n    , values_to = \"value\"\n  ) %>%\n  group_by(sid, trait) %>%\n  summarize(value = mean(value, na.rm = T)) %>%\n  pivot_wider(names_from = \"trait\", values_from = \"value\") %>%\n  ungroup()\n```\n\n## Lesson 7\n\n### Establish a consistent naming scheme\n\n-   label objects relative to a stage or research question\n    -   e.g., `nested_RQ1`, `RQ1_mods`, `raw_df`\n    -   this will help you clear your environment of clutter\n-   use temporary objects repeatedly\n    -   e.g., if you need to use an object as an intermediary step, call it `tmp` and overwrite it as many times as is useful\n    -   You can always remove it using `rm(tmp)`\n\n## Lesson 8\n\n### You won't remember details about raw variables or variables you create, document them\n\n-   Clearly document your raw data and planned transformations before (preregistration) or as (deviations or just reactive responses to aspects of the data) you clean your data\n-   Clearly document all new variables you create, including their scale, etc.\n\n## Lesson 9\n\n### Reference data frames are great keys for ordering and renaming\n\n-   Clearly documenting all new variables you create also creates the opportunity to create **reference data frames**, which can include variable names in the data, category information, longer names for the variables, descriptions of the scales, and the link function / column names e.g.,\n\ncat \\| name \\| scale \\| long_name \\| lab\\\nOutcome \\| dementia \\| 0/1 \\| Clinical Dementia \\| OR \\[CI\\] Outcome \\| braak \\| 1-5 \\| Braak Stage \\| est. \\[CI\\] Predictor \\| E \\| 0-10 \\| Extraversion \\|\\\nPredictor \\| C \\| 0-10 \\| Conscientiousness \\|\\\nModerator \\| age \\| num \\| Baseline Age \\| Moderator \\| ses \\| 1-7 \\| Baseline SES \\|\n\n------------------------------------------------------------------------\n\n### Reference data frames are great keys for ordering and renaming\n\n```{r, eval = F}\nout <- tribble(\n  ~cat,     ~name,        ~scale,      ~long_name,              ~lab,   \n\"Outcome\",  \"dementia\",   \"0/1\",       \"Clinical Dementia\",      \"OR [CI]\",\n\"Outcome\",  \"braak\",      \"1-5\",       \"Braak Stage\",            \"est. [CI]\" \n)\n\ntab %>%\n  left_join(out %>% select(outcome = name, long_out = long_name, lab)) \n```\n\n## Lesson 10\n\n### Reorder everything using factors\n\n-   Often, there are specific orders we want / need strings to be in; this is where factors come in\n-   There's a whole package for this called [`forcats`](https://forcats.tidyverse.org).\n-   Reference data frames are a great way to order your variables\n\n```{r, eval = F}\nout <- tribble(\n  ~cat,     ~name,        ~scale,      ~long_name,              ~lab,   \n\"Outcome\",  \"dementia\",   \"0/1\",       \"Clinical Dementia\",      \"OR [CI]\",\n\"Outcome\",  \"braak\",      \"1-5\",       \"Braak Stage\",            \"est. [CI]\" \n)\n\ntab %>%\n  left_join(out %>% select(outcome = name, long_out = long_name, lab)) %>%\n  mutate(long_out = factor(long_out, levels = out$long_name))\n# mutate(long_out = factor(oucome, levels = out$name, labels = out$long_name))\n```\n\n------------------------------------------------------------------------\n\n### Reorder everything using factors\n\n-   Remember this?\n\n```{r, eval = F}\nterms <- tribble(\n  ~path,     ~new,                         ~level\n  \"i~1\",     \"Intercept\",                  \"Fixed\",\n  \"s~1\",     \"Slope\",                      \"Fixed\",\n  \"i~~i\",    \"Intercept Variance\",         \"Random\",\n  \"s~~s\",    \"Slope Variance\",             \"Random\",\n  \"i~~s\",    \"Intercept-Slope Covariance\", \"Random\"\n)\n\nextract_fun <- function(m, trait){\n  p <- parameterEstimates(m) %>%\n    data.frame()\n  # saveRDS(p, file = sprintf(\"results/summary/%s.RDS\", trait))\n  p %>%\n    unite(path, lhs, op, rhs, sep = \"\") %>%\n    filter(path %in% terms$path) %>%\n    left_join(terms) %>%\n    select(term = new, est, ci.lower, ci.upper, pvalue) %>%\n    mutate(term = factor(term, levels = terms$new)) %>%\n    arrange(term)\n}\n```\n\n## Lesson 11\n\n### Long lists of anything are asking for trouble\n\n-   It took me way too long to even make the short examples above using `tribble()`\n-   Using a spreadsheet is an easier way to compile that information\n-   The `googlesheets4` package is also a package dedicated to helping you to read, write, and parse Google Sheets\n-   It's easy to load files stored on GitHub\n-   Spreadsheets are user friendly even for those who aren't code literate\n-   It's way easier to reorder a spreadsheet (cut-insert cut rows) than to have to move rows around in an R script\n-   f%#\\*ing commas and quotes\n\n## Lesson 12\n\n### File structure and organization are your most important data cleaning & management tools\n\n-   Your data will never be clean if you don't know where your files are!\n-   No one wants to have to rerun things repeatedly\n    -   Store large files (models, bootstrapped resamples, bayesian samples, etc.) using a clear, machine readable, parseable file structure (e.g., `dementia-E-age-unadj.RDS`)\n    -   These can then be read in like:\n\n```{r, eval = F}\nnested_res <- tibble(\n  file = list.files(\"models\"),\n  mod = map(file, \\(x) readRDS(sprintf(\"models/%s\", x)))\n  ) %>%\n  separate(file, c(\"outcome\", \"trait\", \"moderator\", \"adj\"), sep = \"-\")\n```\n\n------------------------------------------------------------------------\n\n### File structure and organization are your most important data cleaning & management tools\n\n-   Same thing goes for smaller objects\n-   Save those small ones, like summaries (e.g., from `broom::tidy()`, `coef()`, etc.), predicted values, random effects, etc. using the same file structure, and you always have everything at your fingertips\n-   Plus you can merge them more easily!\n-   This organization also transfers to GitHub for easy loading via raw links!\n\n## Lesson 13\n\n### Some things / functions are portable across projects, some need modification\n\n-   Some functions are portable:\n\n```{r}\nz_scale <- function(x) (x - mean(x, na.rm = T))/sd(x, na.rm = T)\npomp_score <- function(x){\n  rng <- range(x, na.rm = T)\n  (x - rng[1])/(rng[2] - rng[1])*100\n}\n```\n\n------------------------------------------------------------------------\n\n### Some things / functions are portable across projects, some need modification\n\n-   Some are not:\n-   This function works for `lavaan`. With slight modifications, it could also work for `broom::tidy()` output\n\n```{r, eval = F}\nformat_fun <- function(d){\n  d %>%\n    mutate(sig = ifelse(pvalue < .05, \"sig\", \"ns\")) %>%\n    rowwise() %>%\n    mutate_at(vars(est, ci.lower, ci.upper), round_fun) %>%\n    mutate_at(vars(pvalue), pround_fun) %>%\n    ungroup() %>%\n    mutate(CI = sprintf(\"[%s,%s]\", ci.lower, ci.upper)) %>%\n    mutate_at(vars(est, CI, pvalue), ~ifelse(sig == \"sig\" & !is.na(sig), sprintf(\"<strong>%s</strong>\", .), .)) \n}\n```\n\n------------------------------------------------------------------------\n\n### Some things / functions are portable across projects, some need modification\n\n-   One possibility is to create an `.R` script that you can \"source\" (`source(\"custom_functions.R\")`)\n    -   You could have general functions (e.g., `z_scale()`, `pomp_score()`) and use case specific ones (e.g., `lavaan_format_fun()` or `broom_format_fun()`)\n    -   I often like to copy these into my R workflow because it means that everything is included in the scripts (even though the `.R` script can be included in the repo)\n\n## Lesson 14\n\n### Resources are finite, so be aware of how you're using them\n\n-   Using grid view in your Environment tab is a great way to track resources\n-   The environment below came after running 95 separate models, all of which were held in memory\n\n![](images/full-environment.png)\n\n------------------------------------------------------------------------\n\n### Resources are finite, so be aware of how you're using them\n\n::: nonincremental\n-   Using grid view in your Environment tab is a great way to track resources\n:::\n\n-   The environment below came from reloading smaller summary objects rather than keeping all the models in working memory\n\n![](images/tidy-environment.png)\n\n------------------------------------------------------------------------\n\n### Resources are finite, so be aware of how you're using them\n\n-   Activity Monitor (Mac) or Process Monitor (Windows) is another great way to track general system usage across many programs, not just `R`\n-   I use this in particular when I'm doing parallelization\n    -   Sometimes threads stall (drop to 0% CPU or Memory)\n    -   Sometimes threads use way too much memory (and you start using swap)\n    -   It's great to track this so you can interrupt\n\n## Lesson 15\n\n### Data frames are your friend\n\n-   They are the easiest objects to work with in R because of the number of dedicated tools and functions for working with them\n-   But they can get unwieldy (e.g., printing a data frame with hundreds of columns and thousands of rows)\n-   `tibbles` help with this but don't always play nice\n    -   You can't go from some classes to tibble directly\n    -   Instead go data.frame -\\> tibble\n\n```{r, eval = F}\nr <- cor(df, use = \"pairwise\")\nr[upper.tri(r, diag = T)] <- NA \nr %>%\n  data.frame() %>%\n  as_tibble()\n```\n\n## Lesson 16\n\n### RStudio / Pivot Cheat Sheets\n\n[![Posit Cheatsheets](images/cheatsheets.png)](https://posit.co/resources/cheatsheets/)\n\n------------------------------------------------------------------------\n\n### RStudio / Pivot Cheat Sheets\n\n-   [Quarto](https://rstudio.github.io/cheatsheets/quarto.pdf)\n-   [RStudio](https://rstudio.github.io/cheatsheets/rstudio-ide.pdf)\n-   [RMarkdown](https://rstudio.github.io/cheatsheets/rmarkdown.pdf)\n-   [lubridate](https://rstudio.github.io/cheatsheets/lubridate.pdf)\n-   [stringr](https://rstudio.github.io/cheatsheets/strings.pdf)\n-   [purrr](https://rstudio.github.io/cheatsheets/purrr.pdf)\n-   [readr](https://rstudio.github.io/cheatsheets/data-import.pdf)\n-   [tidyr](https://rstudio.github.io/cheatsheets/tidyr.pdf)\n-   [dplyr](https://rstudio.github.io/cheatsheets/data-transformation.pdf)\n-   [ggplot2](https://rstudio.github.io/cheatsheets/data-visualization.pdf)\n\n## Hacks\n\n-   [The option / alt key and other shortcuts](https://support.posit.co/hc/en-us/articles/200711853-Keyboard-Shortcuts-in-the-RStudio-IDE)\n-   The tab key: \"attempt completion\"\n-   [R templates](https://quarto.org/docs/extensions/starter-templates.html)\n-   [GitHub Pages](https://pages.github.com)\n-   [Functions without inputs](https://bookdown.org/rdpeng/rprogdatascience/functions.html)\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"highlight-style":"tango","self-contained":true,"output-file":"10-week10-workbook.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":"cosmo","title":"Week 10 Workbook","author":"Emorie D Beck","editor_options":{"chunk_output_type":"console"},"code-copy":true,"toc-float":true},"extensions":{"book":{"multiFile":true}}}}}