{"title":"Week 6 Workbook","markdown":{"yaml":{"title":"Week 6 Workbook","author":"Emorie D Beck","format":{"html":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true,"self-contained":true}}},"headingText":"Outline","containsRefs":false,"markdown":"\n\n```{r, echo = F}\nlibrary(knitr)\nlibrary(psych)\nlibrary(lme4)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(kableExtra)\nlibrary(plyr)\nlibrary(tidyverse)\n```\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, \n                      message = FALSE,\t\n                      warning = FALSE,\n                      results = 'show',\n                      fig.width = 4, \n                      fig.height = 4, \n                      fig.retina = 3)\noptions(htmltools.dir.version = FALSE\n        , knitr.kable.NA = \"\")\n```\n\n\n1.  Questions on Homework\n2.  `dplyr`\n3.  `tidyr`\n4.  Functions\n5.  `purrr`\n\n# `dplyr`: `select()` and `filter()`\n\n## 1. `select()`\n\n### Add or remove using `select()` helper functions.\n\n-   `starts_with()`\\\n-   `ends_with()`\n-   `contains()`\n-   `matches()`\n-   `num_range()`\n-   `one_of()`\n-   `all_of()`\n\n```{r, echo = T}\nbfi |>\n  select(starts_with(\"C\"))\n```\n\n## 2. `filter()` {.smaller}\n\n-   Often times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don't want to include.\n\n-   We can use `filter()` with logical statements to include only rows that match certain conditions\n\n-   We can refer to both bare quoted columns and objects in the global environment\n\n    -   `==` or `!=`\n    -   `<` or `<=`\n    -   `>` or `>=`\n    -   `%in%`\n    -   `all_of()`\n    -   `one_of()`\n    -   `!`\n    -   `|` and `&`\n\n# tidyr: `pivot_longer()` and `pivot_wider()`\n\n## 1. `pivot_longer()`\n\n-   (Formerly `gather()`) Makes wide data long, based on a key <font size=\"5\">\n-   Core arguments:\n    -   `data`: the data, blank if piped\n    -   `cols`: columns to be made long, selected via `select()` calls\n    -   `names_to`: name(s) of key column(s) in new long data frame (string or string vector)\n    -   `values_to`: name of values in new long data frame (string)\n    -   `names_sep`: separator in column headers, if multiple keys\n    -   `values_drop_na`: drop missing cells (similar to `na.rm = T`) </font>\n\n### Why would I make my data longer?\n\n-   Main reason: Columns names sometimes contain data.\n-   Example: Billboard data has *time* information in column names\n\n```{r}\ndata(billboard)\nstr(billboard)\n```\n\n```{r}\nbillboard |>\n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    names_prefix = \"wk\",\n    names_transform = as.numeric,\n    values_to = \"rank\"\n  )\n```\n\n-   This doesn't just apply to longitudinal data. This is also important when thinking about iteration.\n-   For example, if you variables can be grouped into different categories (covariates, IVs/predictors, DVs/outcomes, moderators, etc.), then your column names contain *implicit* data\n-   The data below contain *both* time, variable, and category information\n\n```{r}\n# load the codebook\n(codebook <- read_csv(\"week6-codebook.csv\") |>\n    mutate(old_name = str_to_lower(old_name)))\n\nold.names <- codebook$old_name # get old column names\nnew.names <- codebook$new_name # get new column names\nsoep <- read_csv(\"week6-data.csv\") |>\n    select(all_of(old.names))\n```\n\n### Exercise\n\n-   By pivoting our data longer, we can more easily extract information from the column names\n-   Pivot the data below longer. Some hints:\n    -   don't make the procedural or demographic variables long\n    -   split the column names you make long into four chunks:\n        -   \"category\", \"label\", \"item_name\", \"year\"\n    -   drop `NA` values\n\n<!-- ```{r} -->\n\n<!-- soep |> -->\n\n<!--   setNames(new.names) -->\n\n<!-- ``` -->\n\nSolution:\n\n```{r}\nsoep_long <- soep |>\n  setNames(new.names) |>\n  pivot_longer(\n    cols = c(-starts_with(\"Proc\"), -starts_with(\"Dem\"))\n    , names_to = c(\"category\",\t\"label\",\t\"item_name\",\t\"year\")\n    , names_pattern = \"(.*)_(.*)_(.*)_(.*)\"\n    , values_to = \"value\"\n    , values_drop_na = T\n  ) |> mutate(year = as.numeric(year))\nsoep_long\n```\n\n-   Long format data are easier to clean (we'll come back to this but we'll create the cleaned data frame to use for merging practice)\n\n```{r}\nsoep_big5 <- soep_long |>\n  filter(category == \"big5\") |>\n  mutate(value = mapvalues(value, seq(-8,0), rep(NA, 9))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label, year) |>\n  summarize(value = mean(value)) |>\n  ungroup()\n\nsoep_le <- soep_long |>\n  filter(category == \"le\") |>\n  mutate(value = mapvalues(value, seq(-8,1), c(rep(NA, 6), 0, NA, NA, 1))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label) |>\n  summarize(value = sum(value)) |>\n  ungroup()\n\nsoep_clean <- soep_big5 |>\n  rename(trait = label, p_value = value) |>\n  inner_join(\n    soep_le |>\n      rename(le = label, le_value = value)\n  )\n```\n\n## 2. `pivot_wider()` {.smaller}\n\n-   (Formerly `spread()`) Makes wide data long, based on a key <font size=\"6\">\n-   Core arguments:\n    -   `data`: the data, blank if piped\n    -   `names_from`: name(s) of key column(s) in new long data frame (string or string vector)\n    -   `names_sep`: separator in column headers, if multiple keys\n    -   `names_glue`: specify multiple or custom separators of multiple keys\n    -   `values_from`: name of values in new long data frame (string)\n    -   `values_fn`: function applied to data with duplicate labels </font>\n\n### Why would I pivot wider?\n\n-   Some analyses require wide format data\n-   For example, SEM in `lavaan` in R requires that both indicators and time are wide format.\n-   The code below uses the codebook to rename items according to a numbered format that isn't specific to any trait\n\n```{r}\nbig5 <- codebook |> filter(category == \"big5\")\nsoep_lavaan <- soep_long |>\n  filter(category == \"big5\") |>\n  mutate(item_name = mapvalues(item_name, big5$item_name, big5$lavaan_name, warn_missing = F))\nsoep_lavaan\n```\n\n### Exercise\n\n-   Change the `soep_lavaan` data frame to be in wide format using `pivot_wider()`:\n    -   pull the `names` from two sources: `item_name()` and `year`\n\n```{r}\nsoep_lavaan |>\n  pivot_wider(\n    names_from = c(\"item_name\", \"year\")\n    , values_from = \"value\"\n  )\n```\n\n# `dplyr`: \\`\\_join()'\n\n## The `_join()` Functions\n\n-   Often we may need to pull different data from different sources\n-   There are lots of reasons to need to do this\n-   We don't have time to get into all the use cases here, so we'll talk about them in high level terms\n-   We'll focus on:\n    -   `full_join()`\n    -   `inner_join()`\n    -   `left_join()`\n    -   `right_join()`\n\n## 3. `full_join()`\n\n-   Most simply, we can put those back together keeping all observations.\n\n-   Pro: sometimes we want to maintain missing data (i.e. some people are randomly missing variables and we don't want to drop them completely)\n\n-   Con: can leave you with lots of `NA`s\n\n-   Join the codebook to the data below using `full_join()`\n\n-   Look at the data. What's going on here\n\n```{r, eval = F}\nsoep_long |>\n  filter(!category == \"big5\")\n  full_join(\n    # your code here\n  ) |> \n    View()\n```\n\nHere's the solution:\n\n```{r}\nsoep_long |>\n  filter(!category == \"big5\") |>\n  full_join(codebook |> select(category, label, item_name, year, item_text)) \n```\n\n-   note we have lots of missing data because the Big Five portions of the codebook were joined even though we removed that data\n\n## 4. `inner_join()`\n\n-   We can also keep all rows present in *both* data frames\n\n-   Pro: Won't add rows with missing values in key variables\n\n-   Con: will drop observations that you want want for counts, correlations, etc.\n\n-   Join the codebook to the data below using `inner_join()`\n\n-   Look at the data. What's going on here\n\n```{r, eval = F}\nsoep_long |>\n  filter(!category == \"big5\")\n  full_join(\n    # your code here\n  ) |> \n    View()\n```\n\n-   Note that filtering, renaming/selecting, and joining is a common workflow\n\n```{r}\nsoep_long |>\n  filter(category == \"big5\") |>\n  select(Proc_SID, trait = label, item_name, year, p_value = value) |>\n  inner_join(\n    soep_long |>\n    filter(category == \"le\") |>\n    select(Proc_SID, le = label, year, le_value = value)\n  )\n```\n\n## 5. `left_join()`\n\n-   Or all rows present in the left (first) data frame, perhaps if it's a subset of people with complete data\n\n```{r}\nsoep_long |>\n  filter(category == \"big5\") |>\n  select(Proc_SID, trait = label, item_name, year, p_value = value) |>\n  left_join(\n    soep_long |>\n    filter(category == \"le\") |>\n    select(Proc_SID, le = label, year, le_value = value)\n  )\n```\n\n## 6. `right_join()`\n\n-   Or all rows present in the right (second) data frame, such as I do when I join a codebook with raw data\n\n```{r}\nsoep_long |>\n  filter(category == \"big5\") |>\n  select(Proc_SID, trait = label, item_name, year, p_value = value) |>\n  right_join(\n    soep_long |>\n    filter(category == \"le\") |>\n    select(Proc_SID, le = label, year, le_value = value)\n  )\n```\n\n## Your Turn\n\nIn small groups, discuss what's happening when you use `full_join()`, `left_join()`, `right_join()`, `inner_join()`, and `anti_join()` with the code below. Which is correct in this use case?\n\n```{r, eval = F, error = F}\nsoep_long |>\n  filter(category == \"big5\") |>\n  select(Proc_SID, trait = label, item_name, year, p_value = value) |>\n  [x]_join(\n    soep_long |>\n    filter(category == \"le\") |>\n    select(Proc_SID, le = label, year, le_value = value)\n  )\n```\n\n# `dplyr`: split-apply-combine\n\n## Bringing it all together: Split-Apply-Combine\n\n-   Much of the power of `dplyr` functions lay in the split-apply-combine method\n\n-   A given set of of data are:\n\n    -   *split* into smaller chunks\n    -   then a function or series of functions are *applied* to each chunk\n    -   and then the chunks are *combined* back together\n\n## 3. `group_by()`\n\n-   The `group_by()` function is the \"split\" of the method\n-   It basically implicitly breaks the data set into chunks by whatever bare quoted column(s)/variable(s) are supplied as arguments.\n\n## 4. `mutate()`\n\n-   `mutate()` is one of your \"apply\" functions\n-   When you use `mutate()`, the resulting data frame will have the same number of rows you started with\n-   You are directly mutating the existing data frame, either modifying existing columns or creating new ones\n\n## 5. `summarize()` / `summarise()`\n\n-   `summarize()` is one of your \"apply\" functions\n-   The resulting data frame will have the same number of rows as your grouping variable\n-   You number of groups is 1 for ungrouped data frames\n\n# Exercise 1\n\n-   Remember when I said that long format data are easier to clean. Let's do that now.\n\n## Question 1:\n\n-   Let's start with the Big Five data:\n\n1.  `filter()` out only Big Five rows\n2.  `mutate()` each observation so that values less than one are changed to `NA`\n3.  Remove any missing values using `filter()` or `drop_na()`\n4.  Group (split) the data so that you have a \"group\" for each person x trait x year combination\n5.  `summarize()` the values to get a composite score for each Big Five trait for each person in each year:\n\n### Solution\n\nRemember when I said that long format data are easier to clean. Let's do that now.\n\n```{r}\nsoep_big5 <- soep_long |>\n  filter(category == \"big5\") |>\n  mutate(value = mapvalues(value, seq(-8,0), rep(NA, 9))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label, year) |>\n  summarize(value = mean(value)) |>\n  ungroup()\nsoep_big5\n```\n\n## Question 2:\n\nNow let's take care of the life event data:\\\n1. `filter()` out only life event rows\\\n2. `mutate()` each observation so that\n\n-   -2 = 0\n-   1 = 1\n-   everything else is `NA`\n\n3.  Remove any missing values using `filter()` or `drop_na()`\n4.  Group (split) the data so that you have a \"group\" for each person x event combination\n5.  `summarize()` the values to get a `sum` score for each event for each person across all years:\n\n### Solution\n\n```{r}\nsoep_le <- soep_long |>\n  filter(category == \"le\") |>\n  mutate(value = mapvalues(value, seq(-8,1), c(rep(NA, 6), 0, NA, NA, 1))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label) |>\n  summarize(value = sum(value)) |>\n  ungroup()\nsoep_le\n```\n\n## Question 3:\n\nJust for practice, now make your Big Five data frame wide, leaving the time variable (year) long\n\n### Solution\n\n```{r}\nsoep_big5 |>\n  pivot_wider(\n    names_from = \"label\"\n    , values_from = \"value\"\n  )\n```\n\n## Question 4:\n\n-   Now, let's join the data frames back together.\n-   Which join function do you think is most appropriate?\n-   Hint: You will need to rename the `label` and `value` columns to reflect the category of the data\n\n### Solution\n\n```{r}\nsoep_clean <- soep_big5 |>\n  rename(trait = label, p_value = value) |>\n  inner_join(\n    soep_le |>\n      rename(le = label, le_value = value)\n  )\nsoep_clean\n```\n\n# Functions\n\n## Functions\n\n**How to approach writing functions**? (*broad recipe*)\n\n1.  Experiment with performing the task outside of a function\n    -   Experiment with performing task with different sets of inputs\n    -   Often, you must revise this code, when an approach that worked outside a function does not work within a function\n2.  Write the function\n3.  Test the function\n    -   Try to \"break\" it\n4.  **Continual improvement**. As you use the function, make continual improvements going back-and-forth between steps 1-3\n\n## Basics of writing functions\n\n**Three components** of a function:\n\n1.  **Function name**\n    -   Define a function using `function()` and give it a **name** using the assignment operator `<-`\n2.  **Function arguments** (sometimes called \"inputs\")\n    -   Inputs that the function takes; they go inside the parentheses of `function()`\n        -   Can be vectors, data frames, logical statements, strings, etc.\n    -   In the above hypothetical code, the function took three inputs `arg1`, `arg2`, `arg3`, but we could have written:\n        -   `function(x, y, z)` or `function(Larry, Curly, Moe)`\n    -   In the \"function call,\" you specify values to assign to these function arguments\n3.  **Function body**\n    -   What the function does to the inputs\n    -   Function body goes inside the pair of curly brackets (`{}`) that follows `function()`\n    -   Above hypothetical function doesn't do anything, but your function can **return a value** (covered in [later section](#return-values))\n\n# Exercise 2\n\nSome common tasks when working with survey data:\n\n-   Identify number of observations with `NA` values for a specific variable\n-   Identify number of observations with negative values for a specific variable\n-   Replace negative values with `NA` for a specific variable\n\n## `num_negative()` function\n\n**Task**: Write function called `num_negative()`\n\n-   Write a function that counts the number of observations with negative values for a specific variable\n-   Apply this function to variables from dataframe `df` (created below)\n-   Adapted from Ben Skinner's *Programming 1* R Workshop [HERE](https://www.btskinner.me/rworkshop/modules/programming_one.html)\n\n```{r, echo=-c(1:3)}\nset.seed(54321) # so that we all get the same random numbers\ndf <- tibble('id' = 1:100,\n             'age' = sample(c(seq(11,20,1), -97,-98,-99),\n                            size = 100,\n                            replace = TRUE,\n                            prob = c(rep(.09, 10), .1,.1,.1)),\n             'sibage' = sample(c(seq(5,12,1), -97,-98,-99),\n                               size = 100,\n                               replace = TRUE,\n                               prob = c(rep(.115, 8), .1,.1,.1)),\n             'parage' = sample(c(seq(45,55,1), -4,-7,-8),\n                               size = 100,\n                               replace = TRUE,\n                               prob = c(rep(.085, 11), .1,.1,.1))\n)\n\n# Sample dataframe `df` that contains some negative values\ndf\n```\n\n## Steps:\n\n**Recommended steps**:\n\n-   Perform task outside of function\n    -   HINT: `sum(data_frame_name$var_name<0)`\n-   Write function\n-   Apply/test function on variables\n\n### Step 1: Perform task outside of function\n\n```{r}\nnames(df) # identify variable names\ndf$age # print observations for a variable\n\n#BaseR\nsum(df$age<0) # count number of obs w/ negative values for variable \"age\"\n```\n\n### Step 2: Write function\n\n```{r}\nnum_missing <- function(x){\n  sum(x<0)\n}\n```\n\n### Step 3: Apply function\n\n```{r}\nnum_missing(df$age)\nnum_missing(df$sibage)\n```\n\n# Exercise 3:\n\nIn survey data, negative values often refer to reason for missing values:\n\n-   E.g., `-8` refers to \"didn't take survey\"\n-   E.g., `-7` refers to \"took survey, but didn't answer this question\"\n\n## `num_missing()` function\n\n**Task**: Write function called `num_negative()`\n\n-   Write a function that counts number of missing observations for a variable and allows you to specify which values are associated with missing for that variable. This function will take two arguments:\n    -   `x`: The variable (e.g., `df$sibage`)\n    -   `miss_vals`: Vector of values you want to associate with \"missing\" variable\n        -   Values to associate with missing for `df$age`: `-97,-98,-99`\n        -   Values to associate with missing for `df$sibage`: `-97,-98,-99`\n        -   Values to associate with missing for `df$parage`: `-4,-7,-8`\n\n## Steps\n\n**Recommended steps**:\n\n-   Perform task outside of function\n    -   HINT: `sum(data_frame_name$var_name %in% c(-4,-5))`\n-   Write function\n-   Apply/test function on variables\n\n### Step 1: Perform task outside of function\n\n```{r}\nsum(df$age %in% c(-97,-98,-99))\n```\n\n### Step 2: Write function\n\n```{r}\nnum_missing <- function(x, miss_vals){\n\n  sum(x %in% miss_vals)\n}\n```\n\n### Step 3: Apply function\n\n```{r}\nnum_missing(df$age,c(-97,-98,-99))\nnum_missing(df$sibage,c(-97,-98,-99))\nnum_missing(df$parage,c(-4,-7,-8))\n```\n\n# `purrr`\n\n## purrr::`map()`\n\n-   `map()` functions are the tidyverse alternative to for loops and chaotic lists with deep nesting structures\n-   `map()` functions, unlike `_apply()` functions can take any number of inputs, which mimics nested `for` loops\n-   `map()` functions can return any output type, including heterogeneous outputs (at least if you return it as a list)\n\n### Inputs\n\n-   You control how many inputs using the following:\n    -   `map()`: one input, arguments are `map(.x, .f)`\n    -   `map2()`: two inputs, arguments are `map2(.x, y., .f)`\n    -   `pmap()`: any number of inputs, arguments are `pmap(.l, .f)`\n        -   Note the `.l` becuase this means we have to wrap inputs in a `list()`\n\n### Ouputs\n\n-   You can also control the output of `purrr::map()`:\n    -   `map()`: outputs a list\n    -   `map_chr()`: outputs a character vector\\\n    -   `map_dbl()`: outputs a numeric vector\\\n    -   `map_lgl()`: outputs a logical vector\\\n    -   `map_int()`: outputs a integer vector\\\n    -   `map_vec()`: outputs essentially any type of vector\n-   Note that if one input combination fails, all will fail and nothing will be outputted\n\n### Error handling\n\n-   Having everything fail because one thing went wrong is really frustrating\n-   There are a number of functions in `purrr` to help with that:\n    -   `possibly(.f, otherwise)`: returns whatever you ask it return with `otherwise` when a .f call fails\n    -   `safely(.f)`: returns a list with the output, if successful, and errors, if unsuccessful\n    -   Others: see [documentation](https://purrr.tidyverse.org/reference/index.html#adverbs).\n\n### List columns\n\n-   One of the easiest ways to work with `purrr` is using list columns in nested data frames\n\n::: columns\n::: column\n-   You can create a nested data frame using `tidyr::nest()` or `tibble()` (where one column is a list itself)\n\n```{r}\nsoep_clean |>\n  group_by(trait, year, le) |>\n  nest() |>\n  ungroup()\n```\n:::\n\n::: column\n-   You can then call `map()` within a mutate call to modify the list column or create new columns in your data frame\n\n```{r}\ntibble(\n  x = c(1,2,3)\n  , y = list(letters[1:5], letters[6:10], letters[11:15])\n)\n```\n:::\n:::\n\n# Exercise 4\n\n## Question 1:\n\n-   Create a data frame called `soep_nested` that creates a list column of the data split by trait and life event.\n\n### Solution\n\n```{r}\nsoep_nested <- soep_clean |>\n  group_by(trait, le) |>\n  nest() |>\n  ungroup()\n```\n\n## Question 2:\n\n-   Using `mutate()`, create a new list column called `model` that runs the following function\n\n```{r}\nlmer_fun <- function(d){\n  d <- d |> \n    mutate(wave = year - 2005) |>\n    group_by(Proc_SID) |>\n    filter(n() > 1)\n  m <- lmer(p_value ~ wave + le_value + le_value:wave + (1 + wave | Proc_SID), data = d)\n  return(m)\n}\n```\n\n### Solution\n\n```{r}\nsoep_nested <- soep_nested |>\n  mutate(model = map(data, lmer_fun))\nsoep_nested\n```\n\n## Question 3:\n\n-   Use the following function to extract the number of people we estimated slopes for in this model. Output the result as an integer to a new column called `npeople`\n\n```{r}\nnslopes_fun <- function(m) summary(m)$ngrps\n```\n\n### Solution\n\n```{r}\nsoep_nested <- soep_nested |>\n  mutate(npeople = map_int(model, nslopes_fun))\nsoep_nested\n```\n\n## Question 4:\n\n-   Use the `tidy()` function from the `broom.mixed` package to extract the coefficients from the model and their confidence intervals. Save it to the column \"tidy\"\n-   Hints:\n    -   Use the argument `conf.int = T` to get the confidence intervals\n    -   Additional arguments to the `.f` function called in `map()` can be just included as addition arguments (e.g., `map(.x, .f, conf.int = T)`)\n\n### Solution\n\n```{r}\nsoep_nested <- soep_nested |>\n  mutate(tidy = map(model, broom.mixed::tidy, conf.int = T))\n```\n\n## Question 5:\n\n-   Let's practice making a super simple table. Do the following:\n\n1.  remove the data and model columns from the data frame\n2.  `unnest()` the `tidy` column\n3.  Keep only fixed effects (`effect == \"fixed\"`)\n4.  We only care about the interaction, so only keep the interaction `term`\n5.  round the estimate, conf.low, and conf.high columns to 2 decimal places\n6.  Keep the `trait`, `le`, `estimate`, `conf.low`, and `conf.high` columns only\n7.  `pivot_wider()` by trait for `estimate`, `conf.low`, and `conf.high`\n\n### Solution\n\n```{r}\nsoep_tab <- soep_nested |>\n  select(-data, -model) |>\n  unnest(tidy) |>\n  filter(effect == \"fixed\" & grepl(\":\", term)) |>\n  mutate(across(c(estimate, conf.low, conf.high), \\(x) round(x, 2))) |>\n  select(trait, le, estimate, conf.low, conf.high) |>\n  pivot_wider(\n    names_from = \"trait\"\n    , names_glue = \"{trait}_{.value}\"\n    , values_from = c(estimate, conf.low, conf.high)\n  )\nsoep_tab\n```\n\n## Question 6:\n\nUse the function below to get model predictions\n\n```{r}\npred_fun <- function(m){\n  d <- m@frame |>\n      select(-p_value) |>\n      distinct()\n  bind_cols(d, pred = predict(m, newdata = d))\n}\n```\n\n### Solution\n\n```{r}\nsoep_nested <- soep_nested |>\n  mutate(pred = map(model, pred_fun))\nsoep_nested\n```\n\n## Question 7:\n\n-   Let's practice making a super simple table. Do the following:\n\n1.  remove the data, model, and tidy columns from the data frame\n2.  `unnest()` the `tidy` column\n3.  `group_by()` life event and `nest()` + `ungroup()`\n4.  save this as `soep_pred`\n\n### Solution\n\n```{r}\nsoep_pred <- soep_nested |>\n  select(-data, -model, -tidy) |>\n  unnest(pred) |>\n  group_by(trait) |>\n  nest() |>\n  ungroup()\nsoep_pred\n```\n\n## Question 8:\n\n-   Use the following function to create a new column `p` that contains spaghetti plots\n-   Note that the function takes two inputs!\n\n```{r}\nspag_plot_fun <- function(d, trait){\n  set.seed(6)\n  d |>\n    group_by(le) |>\n    nest() |>\n    mutate(data = map(data, ~filter(., Proc_SID %in% sample(unique(.$Proc_SID), 100)))) |>\n    unnest(data) |>\n    ungroup() |>\n    mutate(le_value = ifelse(le_value > 1, 1, le_value)) |>\n    ggplot(aes(x = wave, y = pred)) + \n      geom_line(aes(group = Proc_SID, color = factor(le_value)), alpha = .3) + \n      geom_smooth(method = \"lm\", se = F, color = \"darkblue\") + \n      scale_color_manual(values = c(\"grey\", \"blue\"), labels = c(\"No Event\", \"Event\")) + \n      labs(x = \"Wave\", y = \"Predicted Trait Levels\", color = \"Life Event\", title = trait) + \n      facet_wrap(~le) + \n      theme_classic() + \n      theme(legend.position = c(.7, .1))\n}\n```\n\n### Solution\n\n```{r, fig.width=9}\nsoep_pred <- soep_pred |>\n  mutate(p = map2(data, trait, spag_plot_fun))\n\nsoep_pred$p[[1]]\n```\n\n# Wrap-Up\n\n## Wrap-Up\n\n-   Today's goal was to review the coding concepts we've used so far and ask you to apply them using a series of guided examples\n-   The biggest takeaway I wanted you to have is *chaining*, or how you can use `tidyverse` functions in chains to accomplish a bunch of goals simultaneously\n-   We cleaned, composited, and ran 50 models across thousands of people, including predictions and tables in less than 100 lines of code. Just doing the models, `tidy()`, and `predict()` parts of that alone would have been 150 lines of code and introduced huge opportunities for errors!\n\n# Appendix\n\n## Full Code\n\n### Data\n\n```{r, eval = F}\n# load the codebook\n(codebook <- read_csv(\"week6-codebook.csv\") |>\n    mutate(old_name = str_to_lower(old_name)))\n\nold.names <- codebook$old_name # get old column names\nnew.names <- codebook$new_name # get new column names\nsoep <- read_csv(\"week6-data.csv\") |>\n    select(all_of(old.names))\n\n```\n\n#### Pivot Long\n\n```{r, eval = F}\nsoep_long <- soep |>\n  setNames(new.names) |>\n  pivot_longer(\n    cols = c(-starts_with(\"Proc\"), -starts_with(\"Dem\"))\n    , names_to = c(\"category\",\t\"label\",\t\"item_name\",\t\"year\")\n    , names_pattern = \"(.*)_(.*)_(.*)_(.*)\"\n    , values_to = \"value\"\n    , values_drop_na = T\n  ) |> mutate(year = as.numeric(year))\nsoep_long\n```\n\n#### Recode and Composite\n\n```{r, eval = F}\nsoep_big5 <- soep_long |>\n  filter(category == \"big5\") |>\n  mutate(value = mapvalues(value, seq(-8,0), rep(NA, 9))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label, year) |>\n  summarize(value = mean(value)) |>\n  ungroup()\n\nsoep_le <- soep_long |>\n  filter(category == \"le\") |>\n  mutate(value = mapvalues(value, seq(-8,1), c(rep(NA, 6), 0, NA, NA, 1))) |>\n  drop_na(value) |>\n  group_by(Proc_SID, label) |>\n  summarize(value = sum(value)) |>\n  ungroup()\n\nsoep_clean <- soep_big5 |>\n  rename(trait = label, p_value = value) |>\n  inner_join(\n    soep_le |>\n      rename(le = label, le_value = value)\n  )\n```\n\n### Models\n\n```{r, eval = F}\nsoep_nested <- soep_clean |>\n  group_by(trait, le) |>\n  nest() |>\n  ungroup()\n\nlmer_fun <- function(d){\n  d <- d |> \n    mutate(wave = year - 2005) |>\n    group_by(Proc_SID) |>\n    filter(n() > 1)\n  m <- lmer(p_value ~ wave + le_value + le_value:wave + (1 + wave | Proc_SID), data = d)\n  return(m)\n}\n\nsoep_nested <- soep_nested |>\n  mutate(model = map(data, lmer_fun))\nsoep_nested\n```\n\n### Results\n\n#### Tables\n\n```{r, eval = F}\nnslopes_fun <- function(m) summary(m)$ngrps\n\nsoep_nested <- soep_nested |>\n  mutate(npeople = map_int(model, nslopes_fun))\nsoep_nested\n\nsoep_nested <- soep_nested |>\n  mutate(tidy = map(model, broom.mixed::tidy, conf.int = T))\n\nsoep_tab <- soep_nested |>\n  select(-data, -model) |>\n  unnest(tidy) |>\n  filter(effect == \"fixed\" & grepl(\":\", term)) |>\n  mutate(across(c(estimate, conf.low, conf.high), \\(x) round(x, 2))) |>\n  select(trait, le, estimate, conf.low, conf.high) |>\n  pivot_wider(\n    names_from = \"trait\"\n    , names_glue = \"{trait}_{.value}\"\n    , values_from = c(estimate, conf.low, conf.high)\n  )\nsoep_tab\n```\n\n#### Model Predictions\n\n```{r, eval = F}\npred_fun <- function(m){\n  d <- m@frame |>\n      select(-p_value) |>\n      distinct()\n  bind_cols(d, pred = predict(m, newdata = d))\n}\n\nsoep_nested <- soep_nested |>\n  mutate(pred = map(model, pred_fun))\nsoep_nested\n\nsoep_pred <- soep_nested |>\n  select(-data, -model, -tidy) |>\n  unnest(pred) |>\n  group_by(trait) |>\n  nest() |>\n  ungroup()\nsoep_pred\n\nspag_plot_fun <- function(d, trait){\n  set.seed(6)\n  d |>\n    group_by(le) |>\n    nest() |>\n    mutate(data = map(data, ~filter(., Proc_SID %in% sample(unique(.$Proc_SID), 100)))) |>\n    unnest(data) |>\n    ungroup() |>\n    mutate(le_value = ifelse(le_value > 1, 1, le_value)) |>\n    ggplot(aes(x = wave, y = pred)) + \n      geom_line(aes(group = Proc_SID, color = factor(le_value)), alpha = .3) + \n      geom_smooth(method = \"lm\", se = F, color = \"darkblue\") + \n      scale_color_manual(values = c(\"grey\", \"blue\"), labels = c(\"No Event\", \"Event\")) + \n      labs(x = \"Wave\", y = \"Predicted Trait Levels\", color = \"Life Event\", title = trait) + \n      facet_wrap(~le) + \n      theme_classic() + \n      theme(legend.position = c(.7, .1))\n}\n\nsoep_pred <- soep_pred |>\n  mutate(p = map2(data, trait, spag_plot_fun))\n\nsoep_pred$p[[1]]\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"highlight-style":"tango","self-contained":true,"output-file":"06-week6-workbook.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","theme":"cosmo","title":"Week 6 Workbook","author":"Emorie D Beck","code-copy":true,"toc-float":true},"extensions":{"book":{"multiFile":true}}}}}