[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Cleaning and Management (Fall 2023)",
    "section": "",
    "text": "Mondays, 2:10-5 PM (October 2-December 4, 2023)\n166 Young Hall\nPsychology Department\nUniversity of California, Davis"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Data Cleaning and Management (Fall 2023)",
    "section": "Course Description",
    "text": "Course Description\n\n\n\nIn graduate education, training on research (and statistical) methods and conceptual frameworks far outpaces training on key technical skills that underpin all research, empirical or otherwise. On average, researchers spend about 80% of their (analytic) time on data cleaning, but we spend comparatively little teaching those skills. This course aims to fill that gap by helping researchers to (1) build their reproducible research workflow and (2) improve their data cleaning and general statistical programming skills. To that end, each session will be split to address each of these goals, with the beginning of class focused on conceptual ideas about best practices in building a workflow and the latter half focused on technical training on programming and cleaning data in R. This course will be set up as a “bring your own data” course to allow students to anticipate specific challenges that face different types of research. \nThis course is not a “pure” data science (i.e. we won’t be working with databases, etc.) because it focuses on the skills and tools most common within the social sciences. Science is a collaborative enterprise, and these tools are widely used among many social scientists, which promotes an open, equitable workflow by using tools available and most commonly used by the majority of our peers."
  },
  {
    "objectID": "index.html#navigating-this-site",
    "href": "index.html#navigating-this-site",
    "title": "Data Cleaning and Management (Fall 2023)",
    "section": "Navigating This Site:",
    "text": "Navigating This Site:\n1. Weekly assignments are under Problem Sets. These are due at 12:01 AM on the day of class. \n2. Reading list (and links) and links to workshop slides are under Schedule and on Canvas. I recommend bookmarking this site to allow you access to all materials in perpetuity.\n3. Final Project Information will be under Assignments (added later). Be sure to familiarize yourself with due dates for the final project. More details will be provided on the final project in the coming weeks.\n4. The most updated version of the syllabus will be on the Syllabus page and can be downloaded there as well."
  },
  {
    "objectID": "index.html#course-zoom-link",
    "href": "index.html#course-zoom-link",
    "title": "Data Cleaning and Management (Fall 2023)",
    "section": "Course Zoom Link",
    "text": "Course Zoom Link\nThis course is in person, but you may access it on Zoom due to illness, exposure, travel, etc."
  },
  {
    "objectID": "ps2-week2.html",
    "href": "ps2-week2.html",
    "title": "Problem Set Week 2",
    "section": "",
    "text": "Due Date: Monday, October 16, 12:01 AM PST.\nDownload your problem set for week 2 below or on Canvas.\nAnswers will be posted after the due date."
  },
  {
    "objectID": "01-week1-workbook.html",
    "href": "01-week1-workbook.html",
    "title": "Week 1 Workbook",
    "section": "",
    "text": "You can download the code for this workbook and the rendered workbook here.\n\nCodelibrary(knitr)\nlibrary(psych)\nlibrary(plyr)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.3\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()     masks psych::%+%()\n✖ ggplot2::alpha()   masks psych::alpha()\n✖ dplyr::arrange()   masks plyr::arrange()\n✖ purrr::compact()   masks plyr::compact()\n✖ dplyr::count()     masks plyr::count()\n✖ dplyr::desc()      masks plyr::desc()\n✖ dplyr::failwith()  masks plyr::failwith()\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::id()        masks plyr::id()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::mutate()    masks plyr::mutate()\n✖ dplyr::rename()    masks plyr::rename()\n✖ dplyr::summarise() masks plyr::summarise()\n✖ dplyr::summarize() masks plyr::summarize()"
  },
  {
    "objectID": "01-week1-workbook.html#course-goals-learning-outcomes",
    "href": "01-week1-workbook.html#course-goals-learning-outcomes",
    "title": "Week 1 Workbook",
    "section": "Course Goals & Learning Outcomes",
    "text": "Course Goals & Learning Outcomes\nAfter successful completion of this course, you will be able to:\n\nBuild your own research workflow that can be ported to future projects.\nLearn new programming skills that will help you efficiently, accurately, and deliberately clean and manage your data.\nCreate a bank of code and tools that can be used for a variety of types of research."
  },
  {
    "objectID": "01-week1-workbook.html#course-expectations",
    "href": "01-week1-workbook.html#course-expectations",
    "title": "Week 1 Workbook",
    "section": "Course Expectations",
    "text": "Course Expectations\n\n~50% of the course will be in R\nYou will get the most from this course if you:\n\nhave your own data you can apply course content to\nknow how to clean clean, transform, and manage that data\ntoday’s workshop is a good litmus test for this"
  },
  {
    "objectID": "01-week1-workbook.html#course-materials",
    "href": "01-week1-workbook.html#course-materials",
    "title": "Week 1 Workbook",
    "section": "Course Materials",
    "text": "Course Materials\n\nAll materials (required and optional) are free and online\n\nWickham & Grolemond: R for Data Science https://r4ds.had.co.nz\n\nWickham: Advanced R http://adv-r.had.co.nz\n\n\nData Camp: All paid content unlocked"
  },
  {
    "objectID": "01-week1-workbook.html#assignments",
    "href": "01-week1-workbook.html#assignments",
    "title": "Week 1 Workbook",
    "section": "Assignments",
    "text": "Assignments\n\n\nAssignment Weights\nPercent\n\n\n\nClass Participation\n20%\n\n\nProblem Sets\n40%\n\n\nFinal Project Proposal\n10%*\n\n\nClass Presentation\n10%*\n\n\nFinal Project\n20%*\n\n\nTotal\n100%\n\n\n\nClass Participation\n\nThere are lots of ways to participate, both in and outside class meetings\nClasses will be technologically hybrid\nThe goal of this is for accessibility and to create recordings\nIf you need to miss 2+ classes (i.e. 20+% of total class time), maybe consider taking the course in a different year\nProblem Sets\n\nThe main homework in the course are weekly problem sets\nThe goal is to let you apply concepts from that week to your own data (or whatever data you’ll focus on for the class)\nProblem sets will be posted on Mondays before class\nDue 12:01 AM each Monday (starting next Monday and not including the last day of the course)\nFinal Projects\n\nFinal project replaces final exam (there are no exams)\nThis is a bring your own data class, so the goal of the course is to apply what you’re learning to your own research throughout the term\nDetails of the final project TBD, but will generally include\n\nStage 1: Proposals (due 11/13/23)\nStage 2: In-class presentations (12/04/23)\nStage 3: Final project submission (Due day and time of scheduled final; which I can’t access because ScheduleBuilder thinks I need a CRN for my own course and no one emails me back 🙃)\n\n\nExtra Credit\n\nParticipate in a https://www.tidytuesday.com.\n2 pt extra credit for each one you participate in (max 6 pt total).\nCan post on Twitter or just create a document with the code and output\n\nSubmit on Canvas\n\nIf posting, link the post in the Canvas submission\nIf not posting, attach the knitted file on Canvas"
  },
  {
    "objectID": "01-week1-workbook.html#grading-scale",
    "href": "01-week1-workbook.html#grading-scale",
    "title": "Week 1 Workbook",
    "section": "Grading Scale",
    "text": "Grading Scale\n92.5% - 100% = A; 89.5% - 92.4% = A-\n87.5% - 89.4% = B+; 82.5% - 87.4% = B; 79.5% - 82.4% = B-\n77.5% - 79.4% = C+; 72.5% - 77.4% = C; 69.5% - 72.4% = C-\n67.5% - 69.4% = D+; 62.5% - 67.4% = D; 59.5% - 62.4% = D-\n0% - 59.4% = F"
  },
  {
    "objectID": "01-week1-workbook.html#schedule",
    "href": "01-week1-workbook.html#schedule",
    "title": "Week 1 Workbook",
    "section": "Schedule",
    "text": "Schedule\n\nWeek 1: Intro & Basics\n\nWeek 2: Reproducibility & dplyr\n\nWeek 3: Data Quality & tidyr\n\nWeek 4: Codebooks & importing data\n\nWeek 5: Data structures & transformation\nWeek 6: Versioning & purrr\n\nWeek 7: Efficient R & parallelization\n\nWeek 8: TBD & tables and figures in R\n\nWeek 9: Odds and ends & help with projects\n\nWeek 10: Presentations"
  },
  {
    "objectID": "01-week1-workbook.html#why-should-i-care",
    "href": "01-week1-workbook.html#why-should-i-care",
    "title": "Week 1 Workbook",
    "section": "Why Should I Care?",
    "text": "Why Should I Care?\n\nWhether you like it or not, you have a workflow\nYou have ways you go about doing a project that you maybe haven’t thought too much about\nIssues arise when\n\nA workflow has missing steps\n\nYour workflow is inconsistent across projects\nYour workflow is inefficient, which can lead to mistakes\n\n\nA workflow is a work in progress. If it no longer serves you, let it go"
  },
  {
    "objectID": "01-week1-workbook.html#how-do-i-build-a-workflow",
    "href": "01-week1-workbook.html#how-do-i-build-a-workflow",
    "title": "Week 1 Workbook",
    "section": "How Do I Build a Workflow?",
    "text": "How Do I Build a Workflow?\n\nBuilding a good workflow is both top-down (i.e. big steps to smaller ones) and bottom-up (i.e. necessary smaller steps make certain larger ones necessary)\nWhat?\n\n\n\nExample: New Data Collection\n1. Conceptualization\n2. Funding acquisition\n3. Preregistration\n4. Project Building\n5. Data Collection\n6. Data Cleaning\n7. Data Analysis\n8. Writing (and rewriting)\n9. Submission\n10. Revision (and possibly crying)\n11. ACCEPTANCE\n\nExample: Secondary Data\n1. Conceptualization\n2. Data search\n3. Project Building\n4. Data documentation\n5. Preregistration\n6. Data Cleaning\n7. Data Analysis\n8. Writing (and rewriting)\n9. Submission\n10. Revision (and possibly crying)\n11. ACCEPTANCE\n\n\n\nWorkflows Are Hierarchical: Example – Data Cleaning Steps\n\n\n\nExperimental Data\n1. Gather all data files\n2. Quality checks for each file\n3. Load all files\n4. Merge all files\n5. Check all descriptives\n6. Scoring, coding, and data transformation\n7. Recheck all descriptives\n8. Correlations and visualization\n9. Restructure data for analyses\n\nSecondary Data\n1. Gather all data files\n2. Load each file\n3. Extract variables used\n4. Rename variables, possibly deal with time variables\n4. Merge all files\n5. Check all descriptives\n6. Scoring, coding, and data transformation\n7. Recheck all descriptives\n8. Correlations and visualization\n9. Restructure data for analyses"
  },
  {
    "objectID": "01-week1-workbook.html#workflows-overview-of-the-course",
    "href": "01-week1-workbook.html#workflows-overview-of-the-course",
    "title": "Week 1 Workbook",
    "section": "Workflows: Overview of the Course",
    "text": "Workflows: Overview of the Course\nIn this class, we will focus on building tools for:\n\nDocumenting Data (both before and after collection)\nFile management (how do I build a machine and human navigable directory)\nLoading data files\nAll steps of cleaning data\nRestructuring Data\nDESCRIPTIVES DESCRIPTIVES DESCRIPTIVES\nEfficient Programming (plz stop copy-pasting)\nThis class does not focus on modeling but rather how you get your data set up to run models (Weeks 1-5/6) AND how to extract and present data after you run them (Weeks 6/7-9)\nWe will focus on classes of models in R you will most likely encounter (lm(), glm(), lmer(), nlme(), lavaan, brms)\nIf you run other kinds of models, most tools we will use are portable to many packages and other object classes\nBy the end of this class, my goal is that you:\n\n\nHave a documented workflow for the kind of research you work on\n\nHave a set of tools and skills that apply to each piece of that workflow\n\nHave a skillset that will allow you to adapt and build new workflows for different kinds of research"
  },
  {
    "objectID": "01-week1-workbook.html#what-is-r-why-r",
    "href": "01-week1-workbook.html#what-is-r-why-r",
    "title": "Week 1 Workbook",
    "section": "What is R? Why R?",
    "text": "What is R? Why R?\n\nAn “open source” programming language and software that provide collections of interrelated “functions”\n“open source” means that R is free and created by the user community. The user community can modify basic things about R and add new capabilities to what R can do the user community can modify R and\na “function” is usually something that takes in some “input,” processes this input in some way, and creates some “output”\n\ne.g., the max() function takes as input a collection of numbers (e.g., 3,5,6) and returns as output the number with the maximum value\ne.g., the lm() function takes in as inputs a dataset and a statistical model you specify within the function, and returns as output the results of the regression model"
  },
  {
    "objectID": "01-week1-workbook.html#base-r-vs.-r-packages",
    "href": "01-week1-workbook.html#base-r-vs.-r-packages",
    "title": "Week 1 Workbook",
    "section": "Base R vs. R packages",
    "text": "Base R vs. R packages\n\n\nBase R\n\nWhen you install R, you automatically install the “Base R” set of functions\nExample of a few of the functions in in Base R:\n\n\nas.character() function\n\nprint() function\n\nsetwd() function\n\n\n\n\nR packages\n\nan R “package” (or “library”) is a collection of (related) functions developed by the R community\nExamples of R packages:\n\n\ntidyverse package for manipulating and visualizing data\n\nigraph package for network analyses\n\nleaflet package for mapping\n\nrvest package for webscraping\n\nrtweet package for streaming and downloading data from Twitter\n\n\n\nAll R packages are free!"
  },
  {
    "objectID": "01-week1-workbook.html#why-use-rstudio-pivot",
    "href": "01-week1-workbook.html#why-use-rstudio-pivot",
    "title": "Week 1 Workbook",
    "section": "Why Use RStudio (Pivot)",
    "text": "Why Use RStudio (Pivot)\n\n\n\nAlso free\nBasically a GUI for R\nOrganize files, import data, etc. with ease\nRMarkdown, Quarto, and more are powerful tools (they were used to create these slides!)\nLots of new features and support\n\n\n\nCodeknitr::include_graphics(\"https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/RStudio-Logo-Flat.png\")"
  },
  {
    "objectID": "01-week1-workbook.html#why-use-the-tidyverse",
    "href": "01-week1-workbook.html#why-use-the-tidyverse",
    "title": "Week 1 Workbook",
    "section": "Why Use the tidyverse\n",
    "text": "Why Use the tidyverse\n\n\n\n\nMaintained by RStudio (Pivot)\nNo one should have to use a for loop to change data from long to wide\nTons of integrated tools for data cleaning, manipulation, transformation, and visualization\nEven increasing support for modeling (e.g., tidymodels)\n\n\n\nCodeknitr::include_graphics(\"https://github.com/emoriebeck/psc290-data-viz-2022/raw/main/01-week1-intro/02-code/02-images/tidyverse.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/tidyr.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/stringr.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/shiny.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/rmarkdown.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/quarto.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/knitr.png\")\n\n\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/ggplot2.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/forcats.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/dplyr.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/broom.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/tibble.png\")\n\n\n\n\n\n\n\n\nCodeknitr::include_graphics(\"https://github.com/rstudio/hex-stickers/raw/main/thumbs/purrr.png\")"
  },
  {
    "objectID": "01-week1-workbook.html#why-use-quarto",
    "href": "01-week1-workbook.html#why-use-quarto",
    "title": "Week 1 Workbook",
    "section": "Why use Quarto",
    "text": "Why use Quarto\nQuarto\n\n\n\n\n\nThese slides\n\nThe course website\n\nYour homework\n\nAll written in Quarto"
  },
  {
    "objectID": "01-week1-workbook.html#some-r-basics",
    "href": "01-week1-workbook.html#some-r-basics",
    "title": "Week 1 Workbook",
    "section": "Some R Basics",
    "text": "Some R Basics\nExecuting R commands\nThree ways to execute commands in R\n\nType/copy commands directly into the “console”\n`code chunks’ in RMarkdown (.Rmd files)\n\n\nCmd/Ctrl + Enter: execute highlighted line(s) within chunk\n\nCmd/Ctrl + Shift + k: “knit” entire document\n\n\nR scripts (.R files)\n\n\nCmd/Ctrl + Enter: execute highlighted line(s)\n\nCmd/Ctrl + Shift + Enter (without highlighting any lines): run entire script\n\n\nAssignment\nAssignment refers to creating an “object” and assigning values to it\n\nThe object may be a variable, a dataset, a bit of text that reads “la la la”\n\n<- is the assignment operator\n\nin other languages = is the assignment operator\n\n\ngeneral syntax:\n\nobject_name <- object_values\ngood practice to put a space before and after assignment operator\n\n\nObjects\nR is an “object-oriented” programming language (like Python, JavaScript). So, what is an “object”?\n\nformal computer science definitions are confusing because they require knowledge of concepts we haven’t introduced yet\nMore intuitively, I think objects as anything I assign values to\n\nFor example, below, a and b are the names of objects I assigned values to\n\n\n\n\nCodea <- 5\na\n\n[1] 5\n\nCodeb <- \"yay!\"\nb\n\n[1] \"yay!\"\n\n\n\nBen Skinner says “Objects are like boxes in which we can put things: data, functions, and even other objects.”\nMany commercial statistical software packages (e.g., SPSS, Stata) operate on datasets, which consist of rows of observations and columns of variables\nUsually, these packages can open only one dataset at a time\nBy contrast, in R everything is an object and there is no limit to the number of objects R can hold (except memory)\nVectors\nThe fundamental data structure in R is the “vector”\n\nA vector is a collection of values\nThe individual values within a vector are called “elements”\nValues in a vector can be numeric, character (e.g., “Apple”), or some other type\nBelow we use the combine function c() to create a numeric vector that contains three elements\nHelp file says that c() “combines values into a vector or list”\n\n\nCode#?c # to see help file for the c() \"combine\" function\nx <- c(4, 7, 9) # create object called x, which is a vector with three elements \n# (each an integer)\nx # print object x\n\n[1] 4 7 9\n\n\nVector where the elements are characters\n\nCodeanimals <- c(\"lions\", \"tigers\", \"bears\", \"oh my\") # create object called animals\nanimals\n\n[1] \"lions\"  \"tigers\" \"bears\"  \"oh my\""
  },
  {
    "objectID": "01-week1-workbook.html#exercise",
    "href": "01-week1-workbook.html#exercise",
    "title": "Week 1 Workbook",
    "section": "EXERCISE",
    "text": "EXERCISE\nEither in the R console or within the R markdown file, do the following:\n\nCreate a vector called v1 with three elements, where all the elements are numbers. Then print the values.\nCreate a vector called v2 with four elements, where all the elements are characters (i.e., enclosed in single ’’ or double “” quotes). Then print the values.\nCreate a vector called v3 with five elements, where some elements are numeric and some elements are characters. Then print the values."
  },
  {
    "objectID": "01-week1-workbook.html#solution-to-exercise",
    "href": "01-week1-workbook.html#solution-to-exercise",
    "title": "Week 1 Workbook",
    "section": "Solution to Exercise",
    "text": "Solution to Exercise\n\nCodev1 <- c(1, 2, 3) \n# create a vector called v1 with three elements\n# all the elements are numbers\nv1 # print value\n\n[1] 1 2 3\n\n\n\nCodev2 <- c(\"a\", \"b\", \"c\", \"d\") \n# create a vector called v2 with four elements\n# all the elements are characters\nv2 # print value\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\n\n\nCodev3 <- c(1, 2, 3, \"a\", \"b\") \n# create a vector called v3 with five element\n# some elements are numeric and some elements are characters\nv3 # print value\n\n[1] \"1\" \"2\" \"3\" \"a\" \"b\""
  },
  {
    "objectID": "01-week1-workbook.html#formal-classification-of-vectors-in-r",
    "href": "01-week1-workbook.html#formal-classification-of-vectors-in-r",
    "title": "Week 1 Workbook",
    "section": "Formal classification of vectors in R",
    "text": "Formal classification of vectors in R\n\nHere, I introduce the classification of vectors by Grolemund and Wickham\nThere are two broad types of vectors\n\n\n\nAtomic vectors. An object that contains elements. Six “types” of atomic vectors:\n\n\nlogical, integer, double, character, complex, and raw.\n\n\nInteger and double vectors are collectively known as numeric vectors.\n\n\n\n\n\nLists. Like atomic vectors, lists are objects that contain elements\n\nelements within a list may be atomic vectors\nelements within a list may also be other lists; that is lists can contain other lists\n\n\n\nOne difference between atomic vectors and lists: homogeneous vs. heterogeneous elements\n\natomic vectors are homogeneous: all elements within atomic vector must be of the same type\nlists can be heterogeneous: e.g., one element can be an integer and another element can be character\n\nProblem with this classification:\n\nNot conceptually intutive\nTechnically, lists are a type of vector, but people often think of atomic vectors and lists as fundamentally different things\n\nClassification used by Ben Skinner:\n\ndata type: logical, numeric (integer and double), character, etc.\ndata structure: vector, list, matrix, etc."
  },
  {
    "objectID": "01-week1-workbook.html#using-r-functions",
    "href": "01-week1-workbook.html#using-r-functions",
    "title": "Week 1 Workbook",
    "section": "Using R functions",
    "text": "Using R functions\nWhat are functions\n\nFunctions are pre-written bits of code that accomplish some task.\nFunctions generally follow three sequential steps:\n\n\ntake in an input object(s)\n\nprocess the input.\n\nreturn (A) a new object or (B) a visualizatoin (e.g., plot)\n\n\nFor example, sum() function calculates sum of elements in a vector\n\n\n\ninput. takes in a vector of elements (numeric or logical)\n\nprocessing. Calculates the sum of elements\n\nreturn. Returns numeric vector of length=1; value is sum of input vector\n\n\nCodesum(c(1,2,3))\n\n[1] 6\n\nCodetypeof(sum(c(1,2,3))) # type of object created by sum()\n\n[1] \"double\"\n\nCodelength(sum(c(1,2,3))) # length of object created by sum()\n\n[1] 1\n\n\nFunction syntax\nComponents of a function\n\nfunction name (e.g., sum(), length(), seq())\nfunction arguments\n\nInputs that the function takes, which determine what function does\n\ncan be vectors, data frames, logical statements, etc.\n\n\nIn “function call” you specify values to assign to these function arguments\n\ne.g., sum(c(1,2,3))\n\n\n\nSeparate arguments with a comma ,\n\ne.g., seq(10,15)\n\n\n\n\n\nExample: the sequence function, seq()\n\n\n\nCodeseq(10,15)\n\n[1] 10 11 12 13 14 15\n\n\nFunction syntax: More on function arguments\nUsually, function arguments have names\n\ne.g., the seq() function includes the arguments from, to, by\n\nwhen you call the function, you need to assign values to these arguments; but you usually don’t have to specify the name of the argument\n\n\n\nCodeseq(from=10, to=20, by=2)\n\n[1] 10 12 14 16 18 20\n\nCodeseq(10,20,2)\n\n[1] 10 12 14 16 18 20\n\n\n\nMany function arguments have “default values”, set by whoever wrote the function\n\nif you don’t specify a value for that argument, the default value is inserted\ne.g., partial list of default values for seq(): seq(from=1, to=1, by=1)\n\n\n\n\nCodeseq()\n\n[1] 1\n\nCodeseq(to=10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nCodeseq(10) # R assigned value of 10 to \"to\" rather than \"from\" or \"by\"\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nHelp files for functions\n\n\nTo see help file on a function, type ?function_name without parentheses\n\nCode?sum\n?seq\n\n\n\nContents of help files\n\n\nDescription. What the function does\n\nUsage. Syntax, including default values for arguments\n\nArguments. Description of function arguments\n\nDetails. Details and idiosyncracies of about how the function works.\n\nValue. What (object) the function “returns”\n\ne.g., sum() returns vector of length 1 whose value is sum of input vector\n\n\n\nReferences. Additional reading\n\nSee Also. Related functions\n\nExamples. Examples of function in action\nBottom of help file identifies the package the function comes from"
  },
  {
    "objectID": "01-week1-workbook.html#what-is-quarto",
    "href": "01-week1-workbook.html#what-is-quarto",
    "title": "Week 1 Workbook",
    "section": "What is Quarto",
    "text": "What is Quarto\n\nQuarto documents embed R code, output associated with R code, and text into one document\nAn Quarto document is a “‘Living’ document that updates every time you compile [”Render”] it”\nQuarto documents have the extension .qmd\n\nCan think of them as text files with the extension .qmd rather than .txt\n\n\nAt top of .qmd file you specify the “output” style, which dictates what kind of formatted document will be created\n\ne.g., html_document or pdf_document (this document was created with revealjs)\n\n\nWhen you compile [“Render”] a .qmd file, the resulting formatted document can be an HTML document, a PDF document, an MS Word document, or many other types"
  },
  {
    "objectID": "01-week1-workbook.html#creating-quarto-documents",
    "href": "01-week1-workbook.html#creating-quarto-documents",
    "title": "Week 1 Workbook",
    "section": "Creating Quarto documents",
    "text": "Creating Quarto documents\nDo this with a partner\nApproach for creating a Quarto document.\n\nPoint-and-click from within RStudio\n\nClick on File >> New File >> Quarto Document… >> choose HTML >> click OK\n\nOptional: add title (this is not the file name, just what appears at the top of document)\nOptional: add author name\n\n\nSave the .qmd file; File >> Save As\n\nAny file name\nRecommend you save it in same folder you saved this lecture\n\n\n“Render” the entire .qmd file\n\nPoint-and-click OR shortcut: Cmd/Ctrl + Shift + k"
  },
  {
    "objectID": "01-week1-workbook.html#creating-and-formatting-quarto-documents",
    "href": "01-week1-workbook.html#creating-and-formatting-quarto-documents",
    "title": "Week 1 Workbook",
    "section": "Creating and Formatting Quarto Documents",
    "text": "Creating and Formatting Quarto Documents\nTake a few minutes and have you peruse the Quarto site to build familiarity (I still access it all the time when I forget how to do specific things)\nI especially want you to take some time to peruse documents on YAML headers:\n\nHTML documents\nPDF documents\nWord documents\nWebstes\nRevealJS slides\nBeamer slides\nPowerpoint Slides"
  },
  {
    "objectID": "ps1-week1.html",
    "href": "ps1-week1.html",
    "title": "Problem Set Week 1",
    "section": "",
    "text": "Due Date: Monday, October 9, 12:01 AM PST.\nDownload your problem set for week 1 below or on Canvas.\nAnswers will be posted after the due date."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "After successful completion of this course, you will be able to:\n1.    Build your own research workflow that can be ported to future projects. \n2.    Learn new programming skills that will help you efficiently, accurately, and deliberately clean and manage your data.  \n3.    Create a bank of code and tools that can be used for a variety of types of research."
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\nThere is no official textbook for this course (but if there was, it’d be Wickham, Cetinkaya-Rundel, & Grolemund’s R for Data Science [2nd edition]). However, many of you are coming in with different levels of knowledge and different types of questions, so I am providing some suggested readings below. \nI have arranged for students in this course to receive free access to Data Camp, a library of R (other programming languages) tutorials. Sign up using your UC Davis email here. \nWe will pull from the following two (freely available) books:\nHadley Wickham & Garret Grolemund: R for Data Science\nHadley Wickham: Advanced R \nAll course materials comply with copyright/fair use policies."
  },
  {
    "objectID": "syllabus.html#technology-requirements",
    "href": "syllabus.html#technology-requirements",
    "title": "Syllabus",
    "section": "Technology Requirements",
    "text": "Technology Requirements\nThe lecture presentations, links to articles, assignments, and rubrics are located on this Canvas site for the course and on the Quarto site. To participate in learning activities and complete assignments, you will need:\n\nAccess to a working computer that has a current operating system with updates installed;\nReliable Internet access and a UCD email account;\nA current Internet browser that is compatible with Canvas;\nR and R Studio (see below)\nReliable data storage for your work, such as Box, Office 365, or a USB drive.\n\nWe will do all of our data cleaning work in this class using the R programming language. We will use RStudio to interface with R console for a more user-friendly experience.\nPlease install both R and RStudio before the first day of class. Here’s how:\n\nGet the most recent version of R (free). Download the version of R compatible with your operating system (Mac, Linux, or Windows). If you are running Windows or MacOS, you should choose one of the precompiled binary distributions (i.e., ready-to-run applications; .exe for windows or .pkg for Mac) linked at the top of the R Project’s webpage.\nOnce R is installed, download and install R Studio (soon to be Pivot). R Studio is an “Integrated Development Environment”, or IDE. This means it is a front-end for R that makes it much easier to work with. R Studio is also free, and available for Windows, Mac, and Linux platforms.\nInstall the tidyverse library and several other add-on packages for R. These are sets of tolls or functions that will aid us in cleaning and wrangling data, and more. This is a non-exhaustive list that will get us started.\n\n\nmy_packages <- c(\n  \"plyr\", \"tidyverse\", \"furrr\", \"broom\",\n  \"MASS\", \"quantreg\", \"rlang\", \"scales\",\n  \"survey\", \"srvyr\", \"devtools\", \"future\"\n)\n\ninstall.packages(my_packages, repos = \"http://cran.rstudio.com\")"
  },
  {
    "objectID": "syllabus.html#minimum-technical-skills-needed",
    "href": "syllabus.html#minimum-technical-skills-needed",
    "title": "Syllabus",
    "section": "Minimum Technical Skills Needed",
    "text": "Minimum Technical Skills Needed\nMinimum technical skills are needed in this course. All work in this course must be completed and submitted online through Canvas and all assignments will be completed in R / Rmarkdown / Quarto. Therefore, you must have consistent and reliable access to a computer and the Internet.\nThe basic technical skills you have include the ability to:\n\nOrganize and save electronic files;\nUse UCD email and attached files;\nCheck email and Canvas a few times / week;\nDownload and upload documents;\nLocate information with a browser; and\nUse Canvas.\n\nHowever, you will spend about 50% of this course using R. Therefore, to get the most out of this class, I highly recommend having a better-than-beginner understanding or and experience with the R programming language. R is a skill, just like understanding the components of quality data and workflows, and for the purposes of this course, both are equally necessary and important. If you have any concerns about whether your R skills are strong enough for the course, please talk to the instructor or consider taking the course in a future year."
  },
  {
    "objectID": "syllabus.html#course-assignments-and-grading",
    "href": "syllabus.html#course-assignments-and-grading",
    "title": "Syllabus",
    "section": "Course Assignments and Grading",
    "text": "Course Assignments and Grading\n\nGeneral Assignment Information\n\nAll coursework (assignments) is secured in Canvas with a username and password.\nAll assignments are due on the day indicated on the course schedule.\nComplete rubrics (final project presentations and paper only) will be provided in Canvas.\n\n\n\nWeekly Assignments\nThe goal of this course is not simply to teach you how to clean hypothetical or convenient data. Rather, the goal is to teach you principles of good, accurate, reproducible, and efficient data cleaning and management, how to identify features of high quality data, and how to produce results of analyses efficiently.\nWeekly homework (40%) in this class will focus on programming concepts from that week. Each week, you will complete one problem set, applying the skills you learned that week to your own data. Submit each of these via Canvas by midnight the Sunday before class.\nThese will be graded for completion (you turned it in), relevance (it should be clear that you actually tried to do what you asked), and effort (please show your work). You will not receive feedback on them unless there is an ongoing problem (e.g., lack of depth or effort).\nThis is good opportunity to:\n\nBetter understand challenges with your own data (relative to others)\nReflect on features of your current workflow you like or dislike\nCritique your own work and note ideas to improve (I will probably do this a lot in class!).\nCreate a repository of ideas and code for future research.\n\n\n\nFinal Exam\nThe final exam for this course is instead a final project, due at the day and time of the scheduled final exam. The last day of the course will (likely) be used for presentations on the final project in order to receive feedback from the class and instructor.\nAdditional information on the project will be provided as a separate document on Canvas, announced in week 4 or 5. The project will not be long and the goal will be for you create a document outlining your workflow.\nTo ensure that your workflows are as effective as possible, this will proceed in five parts:\n\nInitial proposal of an idea submitted via Canvas.\nUpdated proposal submitted via Canvas.\n5-10 minute presentation to the class on the last day of the course (10% of your grade).\nFinal Project (20%).\n\n\n\nEvaluation and Grading Scale\nAll grades will be posted on Canvas. You are strongly encouraged to check your scores in Canvas regularly. A final letter grade will be assigned based on percentages.\n\n\n\nAssignment Weights\nPercent\n\n\nClass Participation\n20%\n\n\nProblem Sets\n40%\n\n\nFinal Project Proposal\n10%*\n\n\nClass Presentation\n10%*\n\n\nFinal Project\n20%*\n\n\nTotal\n100%\n\n\n\n* If presentations are omitted, proposals will be worth 15% and Final Projects 25%.\n\nGrading Scale\n92.5% - 100% = A; 89.5% - 92.4% = A-\n87.5% - 89.4% = B+; 82.5% - 87.4% = B; 79.5% - 82.4% = B-\n77.5% - 79.4% = C+; 72.5% - 77.4% = C; 69.5% - 72.4% = C-\n67.5% - 69.4% = D+; 62.5% - 67.4% = D; 59.5% - 62.4% = D-\n0% - 59.4% = F"
  },
  {
    "objectID": "syllabus.html#course-policies-and-procedures",
    "href": "syllabus.html#course-policies-and-procedures",
    "title": "Syllabus",
    "section": "Course Policies and Procedures",
    "text": "Course Policies and Procedures\nMany of the below are also outlined in the UC Davis Code of Academic Conduct.\n\nAttendance Policy\nWhen you miss class, you miss important information, not all of which will be available in the zoom recordings. This course is only 10 class meetings, so each meeting comprises 10% of your in-class time. If you need to miss more than one class, I suggest considering whether taking this course in a future term. I will teach this course either annually or biennially, so there will be future opportunities to take this course in many cases (e.g., for example, if you are a second year student who will miss two meetings, taking the course in your fourth year may be more effective).\n\n\nLate Work/Make-up Policy\nLate work will be allowed per instructor discretion. Please try to proactively communicate these needs. Assignments due at midnight will have a 9 hour “grace period” with no penalty. Each day late is subject to a 20% drop in course grade (e.g., a 10-point response is worth 8 points on day 1 late, 6 points on day 2 late, etc.).\n\n\nAcademic Integrity\nYou are expected to practice the highest possible standards of academic integrity. Any deviation from this expectation will result in a minimum academic penalty of your failing the assignment, and will result in additional disciplinary measures. This includes improper citation of sources, using another student’s work, and any other form of academic misrepresentation.\n\nPlagiarism\nUsing the words or ideas of another as if they were one’s own is a serious form of academic dishonesty. If another person’s complete sentence, syntax, key words, or the specific or unique ideas and information are used, one must give that person credit through proper citation.\n\n\n\nIncomplete Grades\nYou may assigned an ‘I’ (Incomplete) grade if you are unable to complete some portion of the assigned course work because of an unanticipated illness, accident, work-related responsibility, family hardship, or verified learning disability. An Incomplete grade is not intended to give you additional time to complete course assignments or extra credit unless there is indication that the specified circumstances prevented you from completing course assignments on time.\n\n\nInstructional Methods\nThe course will be taught using multiple instructional methods. I will typically briefly (45-50 minutes) lecture at the beginning of the class on conceptual topics related to data cleaning and management. We will then have a 75 minute workshop, which will be a mix of going through code and examples together and working in small groups (if preferred) on short exercises. The remainder of the class will be available to receive support on Problem Sets for that week and other general questions (optional). The proportion of these will vary by week and portions of the course will be shortened or dropped as needed.\n\n\nDiversity and Inclusion\nThe university is committed to a campus environment that is inclusive, safe, and respectful for all persons. To that end, all course activities will be conducted in an atmosphere of friendly participation and interaction among colleagues, recognizing and appreciating the unique experiences, background, and point of view each student brings. You are expected at all times to apply the highest academic standards to this course and to treat others with dignity and respect.\n\nAccessibility, Disability, and Triggers [credit to Dr. David Moscowitz]\nI am committed to ensuring course accessibility for all students. If you have a documented disability and expect reasonable accommodation to complete course requirements, please notify me at least one week before accommodation is needed. Please also provide SDRC (https://sc.edu/about/offices_and_divisions/student_disability_resource_center/) documentation to me before requesting accommodation. Likewise, if you are aware of cognitive or emotional triggers that could disrupt your intellectual or mental health, please let me know so that I can be aware in terms of course content. \nAbsences for Personal or Religious Holidays\nI am committed to allowing students to exercise their rights to religious freedom. Accommodations on assignment due dates and absences will be allowed for students observing religious holidays that fall on course days. Please email me to let me know ahead of time to allow for accommodations to be made.\n\n\nTitle IX and Gendered Pronouns [credit to Dr. David Moscowitz]\nThis course affirms equality and respect for all gendered identities and expressions. Please don’t hesitate to correct me regarding your preferred gender pronoun and/or name if different from what is indicated on the official class roster. Likewise, I am committed to nurturing an environment free from discrimination and harassment. Consistent with Title IX policy, please be aware that I as a responsible employee am obligated to report information that you provide to me about a situation involving sexual harassment or assault. \n\n\nValues [credit to Dr. David Moscowitz]\nTwo core values, inquiry and civility, govern our class. Inquiry demands that we all cultivate an open forum for exchange and substantiation of ideas. Strive to be creative, to take risks, and to challenge our conventional wisdom when you see the opportunity. Civility supports our inquiry by demanding ultimate respect for the voice, rights, and safety of others. Threatening or disruptive conduct may result in course and/or university dismissal. Civility also presumes basic courtesy: please be well rested, on time, and prepared for class (class time also includes a break to use the restroom, etc.), which includes silencing all personal devices. \nMy perspective is that we never cease being students of this world, so I believe that attentive, reflective people always have something to learn from others. Good discussions can be energetic and passionate but are neither abusive nor offensive. Vibrant, vigorous inquiry derives from discussions that:\n\nchallenge, defend, and apply different ideas, theories, perspectives, and skills,\nextend a body of knowledge into different arenas and applications, and\nresult in a synergy that compels us to seek resolution to these discussions.\n\n\n\n\nCopyright/Fair Use\nI will cite and/or reference any materials that I use in this course that I do not create.  You, as students, are expected to not distribute any of these materials, resources, homework assignments, etc. (whether graded or ungraded) without permission from the instructor."
  },
  {
    "objectID": "01-week1-slides.html",
    "href": "01-week1-slides.html",
    "title": "Week 1 Slides",
    "section": "",
    "text": "Welcome to Week 1! This week, we’re just getting started. You can download the slides code and slides here."
  },
  {
    "objectID": "02-week2-slides.html",
    "href": "02-week2-slides.html",
    "title": "Week 2 Slides",
    "section": "",
    "text": "Welcome to Week 2! This week, we’ll talk about R Projects, Reproducibility, and dplyr."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Course Schedule\n\n\n\nDay\nDate\nTopic\nDue Today\n\n\n\n\nFirst Day of Classes September 27\n\n\n\n1\n10/02/2023\nLecture: Basics of Workflow\nWorkshop: Introduction to R & Workflow Basics; Quarto\nReadings:\n-       r4ds: Ch. 3, 5, 7, 29\n\n\n\n2\n10/09/2023\nLecture: Reproducibility and Workflow Values\nWorkshop: Data Transformation: Introduction to dplyr\nReadings:\n-       r4ds: Ch. 4\nProblem Set 1 Due\n\n\n3\n10/16/2023\nLecture: Understanding and Assessing Data Quality\nWorkshop: Reshaping and Joining: Introduction to tidyr\nReadings:\n-       r4ds: Ch. 6\nProblem Set 2 Due\n\n\n4\n10/23/2023\nLecture: Documenting Data and Procedures\nWorkshop: Using Codebooks to Aid Data Import\nReadings:\n-       r4ds: Ch. 8, 21, 24\nProblem Set 3 Due\n\n\n5\n10/30/2023\nLecture: Data Structures in R\nWorkshop: Data Transformation: Dates, Strings, regex, and Other Tricky Classes\nReadings: r4ds: Ch. 13-19\n\n\n\nProblem Set 4 Due\n\n\n6\n11/06/2023\nLecture: Open, Reproducible Science: OSF, GitHub, and Versioning\nWorkshop: Functions and Iteration: Introduction to purrr\nReadings:\n-       r4ds: Ch. 26, 27\nProblem Set 5 Due\n\n\n7\n11/13/2023\nLecture: Using R Resources Efficiently\nWorkshop: Parallelization: Introduction to future and furrr\nReadings:\n-       https://dcgerard.github.io/advancedr/09_future.html\nProblem Set 6 Due\nPROPOSALS DUE\n\n\n8\n11/20/2023\nLecture:\nWorkshop: (Functional) Tables & Figures\nReadings:\n-       TBD (Probably none )\nProblem Set 7 Due\n\n\n\n\nThanksgiving Break\n\n\n\n9\n11/27/2023\nLecture: None (in class help with projects instead)\nWorkshop: Odds, Ends, and Requested Topics\nReadings:\n-       TBD (Probably none )\nProblem Set 8 Due\n\n\n10\n12/04/2023\nIn-Class Presentations\n\n\n\n\n\nFinal Exam"
  },
  {
    "objectID": "02-week2-workbook.html#why-reproducibility-and-values",
    "href": "02-week2-workbook.html#why-reproducibility-and-values",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Why reproducibility AND values?",
    "text": "Why reproducibility AND values?\n\n\nThe definition of reproducibility is somewhat debated\n\n“‘Reproducibility’ refers to instances in which the original researcher’s data and computer codes are used to regenerate the results”\n\n“‘Reproducibility’ refers to independent researchers arriving at the same results using their own data and methods”\n\n\n\nBut regardless of what definition you choose, reproducibility starts with a commitment in research to be\nclear\ntransparent\nhonest\nthorough"
  },
  {
    "objectID": "02-week2-workbook.html#why-reproducibility-and-values-1",
    "href": "02-week2-workbook.html#why-reproducibility-and-values-1",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Why reproducibility AND values?",
    "text": "Why reproducibility AND values?\n\nReproducibility is ethical.\nWhen I post a project, I pour over my code for hours, adding comments, rendering to multiple formats, trying to flag locations in online materials in the mansucript, etc.\nI am trying to prevent errors, but I am also trying to make sure that other people know what I did, especially if I did make errors\nReproducible research is also equitable.\nA reproducible research workflow can be downloaded by another person as a starting point, providing tools to other researchers who may not have the same access to education and resources as you"
  },
  {
    "objectID": "02-week2-workbook.html#where-should-we-reproducible",
    "href": "02-week2-workbook.html#where-should-we-reproducible",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Where should we reproducible?",
    "text": "Where should we reproducible?\n\nPlanning\n\nStudy planning and design\n\nLab Protocols\n\nCodebooks\n\netc.\n\n\n\nAnalyses\n\nScripting\n\nCommunication\n\netc."
  },
  {
    "objectID": "02-week2-workbook.html#aspects-of-reproducibility",
    "href": "02-week2-workbook.html#aspects-of-reproducibility",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Aspects of Reproducibility",
    "text": "Aspects of Reproducibility\n\nData within files should be ‘tidy’ (next week – tidyr)\nProject based approach (today)\nConsistency: naming, space, style (today)\nDocumentation: commenting and README (today)\nLiterate programming e.g. Rmarkdown (every day!)"
  },
  {
    "objectID": "02-week2-workbook.html#reproducible-workflow",
    "href": "02-week2-workbook.html#reproducible-workflow",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Reproducible Workflow",
    "text": "Reproducible Workflow\nA reproducible workflow is organized. What does it mean to be be organized? At least:\n\nUse a project based approach, e.g., RStudio project or similar\n\nHave a hierarchical folder structure\n\nHave a consistent and informative naming system that ‘plays nice’\n\nDocument code with comments and analyses with README\n\n\nMore advanced (later in the class)\n\n\nGeneralize with functions and packages\nversion control"
  },
  {
    "objectID": "02-week2-workbook.html#what-is-a-project",
    "href": "02-week2-workbook.html#what-is-a-project",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "What is a project?",
    "text": "What is a project?\n\nA project is a discrete piece of work which has a number of files associated with it such as the data and scripts for an analysis and the production reports.\nUsing a project-oriented workflow means to have a hierarchical folder structure with everything needed to reproduce an analysis.\n\nOne research project might have several organizational projects associated with it, for example:\n\ndata files and metadata (which may be made into a package)\npreregistration\nanalysis and reporting\na package developed for the analysis\nan app for allowing data to be explored by others"
  },
  {
    "objectID": "02-week2-workbook.html#example",
    "href": "02-week2-workbook.html#example",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Example",
    "text": "Example\nGood Workflows are:\n\nstructured\n\nsystematic\n\nrepeatable\n\nNaming\n\nhuman and machine readable\n\nno spaces\n\nuse snake/kebab case\n\nordering: numbers (zero left padded), dates\n\nfile extensions\n\n\n\n-- ipcs_data_2019\n   |__ipcs_data_2019.Rproj\n   |__data\n      |__raw_data\n         |__2019-03-21_ema_raw.csv\n         |__2019-03-21_baseline_raw.csv\n      |__clean_data\n         |__2019-06-21_ema_long.csv\n         |__2019-06-21_ema_long.RData\n         |__2019-06-21_baseline_wide.csv\n         |__2019-06-21_baseline_wide.RData\n   |__results\n      |__01_models\n         |__E_mortality.RData\n         |__A_mortality.RData\n      |__02_summaries\n         |__E_mortality.RData\n         |__A_mortality.RData\n      |__03_figures\n         |__mortality.png\n         |__mortality.pdf\n      |__04_tables\n         |__zero_order_cors.RData\n         |__descriptives.RData\n         |__key_terms.RData\n         |__all_model_terms.RData\n   |__README.md\n   |__refs\n      |__r_refs.bib\n      |__proj_refs.bib\n   |__analyses\n      |__01_background.Rmd\n      |__02_data_cleaning.Rmd\n      |__03_models.Rmd\n      |__04_summary.Rmd"
  },
  {
    "objectID": "02-week2-workbook.html#what-is-a-path",
    "href": "02-week2-workbook.html#what-is-a-path",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "What is a path?",
    "text": "What is a path?\nA path gives the address - or location - of a filesystem object, such as a file or directory.\n\nPaths appear in the address bar of your browser or file explorer.\nWe need to know a file path whenever we want to read, write or refer to a file using code rather than interactively pointing and clicking to navigate.\nA path can be absolute or relative\n\nabsolute = whole path from root\nrelative = path from current directory\n\n\n\nAbsolute paths\n\nAn Absolute path is given from the “root directory” of the object.\nThe root directory of a file system is the first or top directory in the hierarchy.\nFor example, C:\\ or M:\\ on windows or / on a Mac which is displayed as Macintosh HD in Finder.\n\nThe absolute path for a file, pigeon.txt could be:\n\nwindows: C:/Users/edbeck/Desktop/pigeons/data-raw/pigeon.txt\n\nMac/unix systems: /Users/edbeck/Desktop/pigeons/data-raw/pigeon.txt\n\nweb: http://github.com/emoriebeck/pigeons/data/pigeon.txt\n\nWhat is a directory?\n\nDirectory is the old word for what many now call a folder 📂.\nCommands that act on directories in most programming languages and environments reflect this.\nFor example, in R this means “tell me my working directory”:\ngetwd() get working directory in R\nWhat is a working directory?\n\nThe working directory is the default location a program is using. It is where the program will read and write files by default. You have only one working directory at a time.\nThe terms ‘working directory’, ‘current working directory’ and ‘current directory’ all mean the same thing.\n\nFind your current working directory with:\n\nCodegetwd()\n\n[1] \"/Users/emoriebeck/Documents/teaching/PSC290-cleaning-fall-2023/psc290-data-FQ23/psc290-data-FQ23\"\n\n\nRelative paths\nA relative path gives the location of a filesystem object relative to the working directory, (i.e., that returned by getwd()).\n\nWhen pigeon.txt is in the working directory the relative path is just the file * name: pigeon.txt\nIf there is a folder in the working directory called data-raw and pigeon.txt is in there then the relative path is data-raw/pigeon.txt\nPaths: moving up the hierarchy\n\n../ allows you to look in the directory above the working directory\nWhen pigeon.txt is in folder above the working the relative path is ../pigeon.txt\nAnd if it is in a folder called data-raw which is in the directory above the working directory then the relative path is ../data-raw/pigeon.txt\nWhat’s in my directory?\nYou can list the contents of a directory using the dir() command\n\n\ndir() list the contents of the working directory\n\ndir(\"..\") list the contents of the directory above the working directory\n\ndir(\"../..\") list the contents of the directory two directories above the working directory\n\ndir(\"data-raw\") list the contents of a folder call data-raw which is in the working directory.\nRelative or absolute\n\nMost of the time you should use relative paths because that makes your work portable (i.e. to a different machine / user / etc.).\n🎂 The tab key is your friend!\nYou only need to use absolute paths when you are referring to filesystem outside the one you are using.\n\nI often store the beginning of that path as object.\n\nweb_wd <- “https://github.com/emoriebeck/pigeons/”\nThen I can use sprintf() or paste() to add different endings\n\n\n\n\nCodeweb_wd <- \"https://github.com/emoriebeck/pigeons/\"\nsprintf(\"%s/data-raw/pigeon.txt\", web_wd)\n\n[1] \"https://github.com/emoriebeck/pigeons//data-raw/pigeon.txt\""
  },
  {
    "objectID": "02-week2-workbook.html#example-1",
    "href": "02-week2-workbook.html#example-1",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Example",
    "text": "Example\nDownload and unzip pigeons.zip which has the following structure:\n-- pigeons\n   |__data-processed\n      |__pigeon_long.txt\n   |__data-raw\n      |__pigeon.txt\n   |__figures\n      |__fig1.tiff\n   |__scripts\n      |__analysis.R\n      |__import_reshape.R\n   |__pigeons.Rproj"
  },
  {
    "objectID": "02-week2-workbook.html#rstudio-projects-1",
    "href": "02-week2-workbook.html#rstudio-projects-1",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nProject is obviously a commonly used word. When I am referring to an RStudio Project I will use the capitalised words ‘RStudio Project’ or ‘Project’.\nIn other cases, I will use ‘project’.\nAn RStudio Project is a directory with an .Rproj file in it.\nThe name of the RStudio Project is the same as the name of the top level directory which is referred to as the Project directory.\n\nFor example, if you create an RStudio Project ipcs_data_2019 your folder structure would look something like this:\n-- ipcs_data_2019\n   |__ipcs_data_2019.Rproj\n   |__data\n      |__raw_data\n         |__2019-03-21_ema_raw.csv\n         |__2019-03-21_baseline_raw.csv\n      |__clean_data\n         |__2019-06-21_ema_long.csv\n         |__2019-06-21_ema_long.RData\n         |__2019-06-21_baseline_wide.csv\n         |__2019-06-21_baseline_wide.RData\n   |__results\n      |__01_models\n      |__02_summaries\n      |__03_figures\n      |__04_tables\n   |__README.md\n   |__refs\n      |__r_refs.bib\n      |__proj_refs.bib\n   |__analyses\n      |__01_background.Rmd\n      |__02_data_cleaning.Rmd\n      |__03_models.Rmd\n      |__04_summary.Rmd\n\nthe .RProj file which is the defining feature of an RStudio Project\nWhen you open an RStudio Project, the working directory is set to the Project directory (i.e., the location of the .Rproj file).\nThis makes your work portable. You can zip up the project folder and send it to any person, including future you, or any computer.\nThey will be able to unzip, open the project and have all the code just work.\n(This is great for sending code and/or results to your advisors)"
  },
  {
    "objectID": "02-week2-workbook.html#directory-structure",
    "href": "02-week2-workbook.html#directory-structure",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Directory structure",
    "text": "Directory structure\nYou are aiming for structured, systematic and repeatable. For example, the Project directory might contain:\n\n.RProj file\n\nREADME - tell people what the project is and how to use it\n\nLicense - tell people what they are allowed to do with your project\nDirectories\ndata/\n\nprereg/\n\nscripts/\nresults/\n\nmanuscript/"
  },
  {
    "objectID": "02-week2-workbook.html#readme",
    "href": "02-week2-workbook.html#readme",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "README",
    "text": "README\n\nREADMEs are a form of documentation which have been widely used for a long time. They contain all the information about the other files in a directory. They can be extensive.\nWikipedia README page\nGitHub Doc’s About READMEs\nOSF\n\nA minimal README might give:\n\nTitle\nDescription, 50 words or so on what the project is\nTechnical Description of the project\n\nWhat software and packages are needed including versions\nAny instructions needed to run the analysis/use the software\nAny issues that a user might face in running the analysis/using the software\n\n\nInstructions on how to use the work\nLinks to where other files, materials, etc. are stored\n\nE.g., an OSF readme may point to GitHub, PsyArxiv, etc."
  },
  {
    "objectID": "02-week2-workbook.html#license",
    "href": "02-week2-workbook.html#license",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "License",
    "text": "License\nA license tells others what they can and can’t do with your work.\nchoosealicense.com is a useful explainer.\nI typically use:\n\n\nMIT License for software\n\nCC-BY-SA-4.0 for other work"
  },
  {
    "objectID": "02-week2-workbook.html#rstudio-project-infrastructure",
    "href": "02-week2-workbook.html#rstudio-project-infrastructure",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "RStudio Project infrastructure",
    "text": "RStudio Project infrastructure\n🎬 create a new Project called iris by:\n\nclicking File->New Project…\nclicking on the little icon (second from the left) at the top\nChoose New Project, then New Directory, then New Project. Name the RStudio Project iris.\nCreate folders in iris called data-raw, data-processed and figures.\nStart new scripts called 01-import.R, 02-tidy.R, and 03-figures.R"
  },
  {
    "objectID": "02-week2-workbook.html#save-and-import",
    "href": "02-week2-workbook.html#save-and-import",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Save and Import",
    "text": "Save and Import\n\nSave a copy of iris.csv to your data-raw folder. These data give the information about different species of irises.\nIn your 01-import.R script, load the tidyverse set of packages.\n\n\nCodelibrary(tidyverse)\nwrite_csv(iris, file = \"data-raw/iris.csv\")\n\n\n\nAdd the command to import the data:\n\n\nCodeiris <- read_csv(\"data-raw/iris.csv\")\n\n\n\n\n\n\nThe relative path is data-raw/iris.csv because your working directory is the Project directory, iris."
  },
  {
    "objectID": "02-week2-workbook.html#reformat-the-data",
    "href": "02-week2-workbook.html#reformat-the-data",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Reformat the data",
    "text": "Reformat the data\nThis dataset has three observations in a row - it is not ‘tidy’.\n\nOpen your 02-tidy.R script, and reshape the data using:\n\n\nCodeiris <- pivot_longer(data = iris, \n                     cols = -Species, \n                     names_to = \"attribute\", \n                     values_to = \"value\")\n\n\n\nThis reformats the dataframe in R but does not overwrite the text file of the data.\nDon’t worry too much about this right now. We’ll spend a lot of time talking about reshaping data next week!"
  },
  {
    "objectID": "02-week2-workbook.html#writing-files",
    "href": "02-week2-workbook.html#writing-files",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Writing files",
    "text": "Writing files\nOften we want to write to files.\n\nMy main reasons for doing so are to save copies of data that have been processed and to save manuscripts and graphics.\nAlso, as someone who collects a lot of data, the de-identified, fully anonymized data files I can share and the identifiable data I collect require multiple versions (and encryption, keys, etc.)\nWrite your dataframe iris to a csv file named iris-long.csv in your data-processed folder:\n\n\nCodefile <- \"data-processed/iris-long.csv\"\nwrite_csv(iris, file)\n\n\n\n\n\n\nPutting file paths into variables often makes your code easier to read especially when file paths are long or used multiple times."
  },
  {
    "objectID": "02-week2-workbook.html#create-a-plot",
    "href": "02-week2-workbook.html#create-a-plot",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Create a plot",
    "text": "Create a plot\nOpen your 03-figures.R script and create a simple plot of this data with:\n\nCodefig1 <- ggplot(\n  data = iris\n  , aes(y = Species, x = value, fill = Species)\n  ) + \n  geom_boxplot() +                       \n  facet_grid(attribute~.) + \n  scale_x_continuous(name = \"Attribute\") +\n  scale_y_discrete(name = \"Species\") +\n  theme_classic() + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "02-week2-workbook.html#view-plot",
    "href": "02-week2-workbook.html#view-plot",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "View plot",
    "text": "View plot\nView plot with:\n\nCodefig1"
  },
  {
    "objectID": "02-week2-workbook.html#write-ggplot-figure-to-file",
    "href": "02-week2-workbook.html#write-ggplot-figure-to-file",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Write ggplot figure to file",
    "text": "Write ggplot figure to file\n\nA useful function for saving ggplot figures is ggsave().\nIt has arguments for the size, resolution and device for the image. See the ggsave() reference page.\nSince I often make more than one figure, I might set these arguments first.\n\n\n\n\nAssign ggsave argument values to variables:\n\n\nCode# figure saving settings\nunits <- \"in\"  \nfig_w <- 3.2\nfig_h <- fig_w\ndpi <- 600\ndevice <- \"tiff\" \n\n\n\n\nSave the figure to your figures directory:\n\n\nCodeggsave(\"figures/fig1.tiff\",\n       plot = fig1,\n       device = device,\n       width = fig_w,\n       height = fig_h,\n       units = units,\n       dpi = dpi)\n\n\n\n\n\n\nCheck it is there!\n\n\n\n\n\n\n\nData Manipulation in dplyr"
  },
  {
    "objectID": "02-week2-workbook.html#core-functions",
    "href": "02-week2-workbook.html#core-functions",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "Core Functions",
    "text": "Core Functions\n\n\n\n\n%>%\nfilter()\nselect()\narrange()\ngroup_by()\nmutate()\nsummarize()\n\n\n\nAlthough each of these functions are powerful alone, they are incredibly powerful in conjunction with one another. So below, I’ll briefly introduce each function, then link them all together using an example of basic data cleaning and summary."
  },
  {
    "objectID": "02-week2-workbook.html#section",
    "href": "02-week2-workbook.html#section",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "1. %>%\n",
    "text": "1. %>%\n\n\nThe pipe %>% is wonderful. It makes coding intuitive. Often in coding, you need to use so-called nested functions. For example, you might want to round a number after taking the square of 43.\n\n\nCodesqrt(43)\n\n[1] 6.557439\n\nCoderound(sqrt(43), 2)\n\n[1] 6.56\n\n\nThe issue with this comes whenever we need to do a series of operations on a data set or other type of object. In such cases, if we run it in a single call, then we have to start in the middle and read our way out.\n\nCoderound(sqrt(43/2), 2)\n\n[1] 4.64\n\n\nThe pipe solves this by allowing you to read from left to right (or top to bottom). The easiest way to think of it is that each call of %>% reads and operates as “and then.” So with the rounded square root of 43, for example:\n\nCodesqrt(43) %>%\n  round(2)\n\n[1] 6.56"
  },
  {
    "objectID": "02-week2-workbook.html#filter",
    "href": "02-week2-workbook.html#filter",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "2. filter()\n",
    "text": "2. filter()\n\nOften times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don’t want to include.\n\n\nCodedata(bfi) # grab the bfi data from the psych package\nbfi <- bfi %>% as_tibble()\nhead(bfi)\n\n\n\n  \n\n\n\nOften times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don’t want to include.\n\nCodesummary(bfi$age) # get age descriptives\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3.00   20.00   26.00   28.78   35.00   86.00 \n\n\nOften times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don’t want to include.\n\nCodebfi2 <- bfi %>% # see a pipe!\n  filter(age <= 18) # filter to age up to 18\n\nsummary(bfi2$age) # summary of the new data \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0    16.0    17.0    16.3    18.0    18.0 \n\n\nBut this isn’t quite right. We still have folks below 12. But, the beauty of filter() is that you can do sequence of OR and AND statements when there is more than one condition, such as up to 18 AND at least 12.\n\nCodebfi2 <- bfi %>%\n  filter(age <= 18 & age >= 12) # filter to age up to 18 and at least 12\n\nsummary(bfi2$age) # summary of the new data \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    16.0    17.0    16.4    18.0    18.0 \n\n\nGot it!\n\nBut filter works for more use cases than just conditional\n\n\n<, >, <=, and >=\n\n\n\nIt can also be used for cases where we want a single values to match cases with text.\nTo do that, let’s convert one of the variables in the bfi data frame to a string.\nSo let’s change gender (1 = male, 2 = female) to text (we’ll get into factors later).\n\n\nCodebfi$education <- plyr::mapvalues(bfi$education, 1:5, c(\"Below HS\", \"HS\", \"Some College\", \"College\", \"Higher Degree\"))\n\n\nNow let’s try a few things:\n1. Create a data set with only individuals with some college (==).\n\nCodebfi2 <- bfi %>% \n  filter(education == \"Some College\")\nunique(bfi2$education)\n\n[1] \"Some College\"\n\n\n2. Create a data set with only people age 18 (==).\n\nCodebfi2 <- bfi %>%\n  filter(age == 18)\nsummary(bfi2$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     18      18      18      18      18      18 \n\n\n3. Create a data set with individuals with some college or above (%in%).\n\nCodebfi2 <- bfi %>%\n  filter(education %in% c(\"Some College\", \"College\", \"Higher Degree\"))\nunique(bfi2$education)\n\n[1] \"Some College\"  \"Higher Degree\" \"College\"      \n\n\n%in% is great. It compares a column to a vector rather than just a single value, you can compare it to several\n\nCodebfi2 <- bfi %>%\n  filter(age %in% 12:18)\nsummary(bfi2$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    16.0    17.0    16.4    18.0    18.0"
  },
  {
    "objectID": "02-week2-workbook.html#select",
    "href": "02-week2-workbook.html#select",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "3. select()\n",
    "text": "3. select()\n\n\nIf filter() is for pulling certain observations (rows), then select() is for pulling certain variables (columns).\nit’s good practice to remove these columns to stop your environment from becoming cluttered and eating up your RAM.\nIn our bfi data, most of these have been pre-removed, so instead, we’ll imagine we don’t want to use any indicators of Agreeableness (A1-A5) and that we aren’t interested in gender.\nWith select(), there are few ways choose variables. We can bare quote name the ones we want to keep, bare quote names we want to remove, or use any of a number of select() helper functions.\n\nA. Bare quote columns we want to keep:\n\n\n\nCodebfi %>%\n  select(C1, C2, C3, C4, C5) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 5\n     C1    C2    C3    C4    C5\n  <int> <int> <int> <int> <int>\n1     2     3     3     4     4\n2     5     4     4     3     4\n3     4     5     4     2     5\n4     4     4     3     5     5\n5     4     4     5     3     2\n6     6     6     6     1     3\n# ℹ 2,794 more rows\n\n\n\n\nCodebfi %>%\n  select(C1:C5) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 5\n     C1    C2    C3    C4    C5\n  <int> <int> <int> <int> <int>\n1     2     3     3     4     4\n2     5     4     4     3     4\n3     4     5     4     2     5\n4     4     4     3     5     5\n5     4     4     5     3     2\n6     6     6     6     1     3\n# ℹ 2,794 more rows\n\n\n\n\n\nB. Bare quote columns we don’t want to keep:\n\nCodebfi %>% \n  select(-(A1:A5), -gender) %>% # Note the `()` around the columns\n  print(n = 6)\n\n# A tibble: 2,800 × 22\n     C1    C2    C3    C4    C5    E1    E2    E3    E4    E5    N1    N2    N3\n  <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <int>\n1     2     3     3     4     4     3     3     3     4     4     3     4     2\n2     5     4     4     3     4     1     1     6     4     3     3     3     3\n3     4     5     4     2     5     2     4     4     4     5     4     5     4\n4     4     4     3     5     5     5     3     4     4     4     2     5     2\n5     4     4     5     3     2     2     2     5     4     5     2     3     4\n6     6     6     6     1     3     2     1     6     5     6     3     5     2\n# ℹ 2,794 more rows\n# ℹ 9 more variables: N4 <int>, N5 <int>, O1 <int>, O2 <int>, O3 <int>,\n#   O4 <int>, O5 <int>, education <chr>, age <int>\n\n\nC. Add or remove using select() helper functions.\n\n\n\n\nstarts_with()\n\nends_with()\ncontains()\nmatches()\nnum_range()\none_of()\nall_of()\n\n\n\n\nCodebfi %>%\n  select(starts_with(\"C\"))"
  },
  {
    "objectID": "02-week2-workbook.html#arrange",
    "href": "02-week2-workbook.html#arrange",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "4. arrange()\n",
    "text": "4. arrange()\n\n\nSometimes, either in order to get a better sense of our data or in order to well, order our data, we want to sort it\nAlthough there is a base R sort() function, the arrange() function is tidyverse version that plays nicely with other tidyverse functions.\n\n\nSo in our previous examples, we could also arrange() our data by age or education, rather than simply filtering. (Or as we’ll see later, we can do both!)\n\n\nCode# sort by age\nbfi %>% \n  select(gender:age) %>%\n  arrange(age) %>% \n  print(n = 6)\n\n# A tibble: 2,800 × 3\n  gender education       age\n   <int> <chr>         <int>\n1      1 Higher Degree     3\n2      2 <NA>              9\n3      2 Some College     11\n4      2 <NA>             11\n5      2 <NA>             11\n6      2 <NA>             12\n# ℹ 2,794 more rows\n\n\n\n\nCode# sort by education\nbfi %>%\n  select(gender:age) %>%\n  arrange(education) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 3\n  gender education   age\n   <int> <chr>     <int>\n1      1 Below HS     19\n2      1 Below HS     21\n3      1 Below HS     17\n4      1 Below HS     18\n5      1 Below HS     18\n6      2 Below HS     18\n# ℹ 2,794 more rows\n\n\n\n\nWe can also arrange by multiple columns, like if we wanted to sort by gender then education:\n\nCodebfi %>%\n  select(gender:age) %>%\n  arrange(gender, education) %>% \n  print(n = 6)\n\n# A tibble: 2,800 × 3\n  gender education   age\n   <int> <chr>     <int>\n1      1 Below HS     19\n2      1 Below HS     21\n3      1 Below HS     17\n4      1 Below HS     18\n5      1 Below HS     18\n6      1 Below HS     32\n# ℹ 2,794 more rows"
  },
  {
    "objectID": "02-week2-workbook.html#group_by",
    "href": "02-week2-workbook.html#group_by",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "5. group_by()\n",
    "text": "5. group_by()\n\n\nThe group_by() function is the “split” of the method\nIt basically implicitly breaks the data set into chunks by whatever bare quoted column(s)/variable(s) are supplied as arguments.\n\nSo imagine that we wanted to group_by() education levels to get average ages at each level\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 8\n# Groups:   education [6]\n     C1    C2    C3    C4    C5   age gender education   \n  <int> <int> <int> <int> <int> <int>  <int> <chr>       \n1     2     3     3     4     4    16      1 <NA>        \n2     5     4     4     3     4    18      2 <NA>        \n3     4     5     4     2     5    17      2 <NA>        \n4     4     4     3     5     5    17      2 <NA>        \n5     4     4     5     3     2    17      1 <NA>        \n6     6     6     6     1     3    21      2 Some College\n# ℹ 2,794 more rows\n\n\n\nHadley’s first law of data cleaning: “What is split, must be combined”\nThis is super easy with the ungroup() function:\n\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education) %>%\n  ungroup() %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 8\n     C1    C2    C3    C4    C5   age gender education   \n  <int> <int> <int> <int> <int> <int>  <int> <chr>       \n1     2     3     3     4     4    16      1 <NA>        \n2     5     4     4     3     4    18      2 <NA>        \n3     4     5     4     2     5    17      2 <NA>        \n4     4     4     3     5     5    17      2 <NA>        \n5     4     4     5     3     2    17      1 <NA>        \n6     6     6     6     1     3    21      2 Some College\n# ℹ 2,794 more rows\n\n\nMultiple group_by() calls overwrites previous calls:\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education) %>%\n  group_by(gender, age) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 8\n# Groups:   gender, age [115]\n     C1    C2    C3    C4    C5   age gender education   \n  <int> <int> <int> <int> <int> <int>  <int> <chr>       \n1     2     3     3     4     4    16      1 <NA>        \n2     5     4     4     3     4    18      2 <NA>        \n3     4     5     4     2     5    17      2 <NA>        \n4     4     4     3     5     5    17      2 <NA>        \n5     4     4     5     3     2    17      1 <NA>        \n6     6     6     6     1     3    21      2 Some College\n# ℹ 2,794 more rows"
  },
  {
    "objectID": "02-week2-workbook.html#mutate",
    "href": "02-week2-workbook.html#mutate",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "6. mutate()\n",
    "text": "6. mutate()\n\n\n\nmutate() is one of your “apply” functions\nWhen you use mutate(), the resulting data frame will have the same number of rows you started with\nYou are directly mutating the existing data frame, either modifying existing columns or creating new ones\n\nTo demonstrate, let’s add a column that indicated average age levels within each age group\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  group_by(education) %>% \n  mutate(age_by_edu = mean(age, na.rm = T)) %>%\n  print(n = 6)\n\n# A tibble: 2,800 × 9\n# Groups:   education [6]\n     C1    C2    C3    C4    C5   age gender education age_by_edu\n  <int> <int> <int> <int> <int> <int>  <int> <chr>          <dbl>\n1     6     6     3     4     5    19      1 Below HS        25.1\n2     4     3     5     3     2    21      1 Below HS        25.1\n3     5     5     5     2     2    17      1 Below HS        25.1\n4     5     5     4     1     1    18      1 Below HS        25.1\n5     4     5     4     3     3    18      1 Below HS        25.1\n6     3     2     3     4     6    18      2 Below HS        25.1\n# ℹ 2,794 more rows\n\n\nmutate() is also super useful even when you aren’t grouping\nWe can create a new category\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  mutate(gender_cat = plyr::mapvalues(gender, c(1,2), c(\"Male\", \"Female\")))\n\n\n\n  \n\n\n\nWe could also just overwrite it:\n\nCodebfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  mutate(gender = plyr::mapvalues(gender, c(1,2), c(\"Male\", \"Female\")))"
  },
  {
    "objectID": "02-week2-workbook.html#summarize-summarise",
    "href": "02-week2-workbook.html#summarize-summarise",
    "title": "Week 2: Reproducibility and Data Transformations",
    "section": "7. summarize() / summarise()\n",
    "text": "7. summarize() / summarise()\n\n\n\nsummarize() is one of your “apply” functions\nThe resulting data frame will have the same number of rows as your grouping variable\nYou number of groups is 1 for ungrouped data frames\n\n\nCode# group_by() education\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  group_by(education) %>% \n  summarize(age_by_edu = mean(age, na.rm = T))  \n\n\n\n  \n\n\n\n\nCode# no groups  \nbfi %>% \n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  summarize(age_by_edu = mean(age, na.rm = T))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr. Emorie D. Beck (she/her/hers)\nE-mail: edbeck@ucdavis.edu\nOffice: 268J\n- Office Hours: TBD as fall schedules finalize\n- Drop-in hour:\n- One-on-one hour: - By other appointment: edbeck@ucdavis.edu\n\n\n\n\n\n\nDr. Beck is an Assistant Professor in the Psychology Department specializing in personality psychology. She received her PhD in Social and Personality Psychology from Washington University in St. Louis in 2020 and her BA (with honors) from Brown University in 2016. \nDr. Beck’s research focuses around the question of what personality is. Definitions have big consequences for how we measure personality, what those measures predict both short- and long-term, how personality is thought to change, and more. One way of doing this is to focus on different levels of aggregation. Thus, she studies how to understand the personality of an individual relative to only themself, relative to some others, and relative to all others. To do so, she uses a mix of methods, including experience sampling methods, passive sensing, survey data, panel data, cognitive tests, and more measured across time intervals from moments to years along with an array of statistical approaches, including time series analysis, multilevel / hierarchical modeling, machine learning, network psychometrics, structural equation modeling, and more. For example, Dr. Beck has been working to build personalized machine learning prediction of behaviors, experiences, and more, finding that we can predict behaviors and experiences better when we don’t assume that people have the same antecedents of the behaviors and experiences.  Instead, people have unique antecedents, which could have consequences for how to change or intervene upon behaviors and experiences. In other work, Dr. Beck uses longitudinal panel data across multiple continents to answer questions about what personality traits predict over time. For example, she recently examined personality trait and well-being predictors of later dementia diagnoses and neuropathology measures after death, finding that personality traits are strong predictors of dementia diagnosis but have a much more complex relationship with neuropathology measures."
  }
]